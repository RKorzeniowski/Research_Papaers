<!DOCTYPE html>
<html class="gr__adeshpande3_github_io"><head>
    <link rel="icon" type="image/png" href="https://adeshpande3.github.io/assets/favicon-32x32.png" sizes="32x32">
    <title>A Beginner's Guide To Understanding Convolutional Neural Networks Part 2 – Adit Deshpande – CS Undergrad at UCLA ('19)</title>

        <meta charset="utf-8">
    <meta content="text/html; charset=UTF-8" http-equiv="Content-Type">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">
    <link rel="image_src" type="image/png" href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/img_path">

    
    <meta name="description" content="ReLUs, Pooling, Dropout...(aka The Fun Stuff)">
    <meta property="og:description" content="ReLUs, Pooling, Dropout...(aka The Fun Stuff)">
    <meta property="og:image" content="">
    
    <meta name="author" content="Adit Deshpande">

    
    <meta property="og:title" content="A Beginner's Guide To Understanding Convolutional Neural Networks Part 2">
    <meta property="twitter:title" content="A Beginner's Guide To Understanding Convolutional Neural Networks Part 2">
    


    <!--[if lt IE 9]>
      <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <link rel="stylesheet" type="text/css" href="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/style.css">
    <link rel="alternate" type="application/rss+xml" title="Adit Deshpande - CS Undergrad at UCLA ('19)" href="https://adeshpande3.github.io/adeshpande3.github.io/feed.xml">



	<!-- Google Analytics -->
	<script async="" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/analytics.js"></script><script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-80811190-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/',
		  'title': 'A Beginner\'s Guide To Understanding Convolutional Neural Networks Part 2'
		});
	</script>
	<!-- End Google Analytics -->





    <!-- Created with Jekyll Now - http://github.com/barryclark/jekyll-now -->
  <script type="text/javascript" async="" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/embed.js"></script><link rel="prefetch" as="style" href="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/a_data/lounge.css"><link rel="prefetch" as="script" href="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/a_data/common.js"><link rel="prefetch" as="script" href="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/a_data/lounge.js"><link rel="prefetch" as="script" href="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/a_data/config.js"><script type="text/javascript" charset="utf-8" async="" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/button.js"></script><script src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/alfalfa.js" async="" charset="UTF-8"></script></head>

  <body data-gr-c-s-loaded="true">
    <div class="wrapper-masthead">
      <div class="container">
        <header class="masthead clearfix">
          <a href="https://adeshpande3.github.io/adeshpande3.github.io/" class="site-avatar"><img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/AAEAAQAAAAAAAAI-AAAAJDY5YmU0MmU0LWU2NzctNDI4Zi04ZTk4LTdlNjE1.jpg"></a>

          <div class="site-info">
            <h1 class="site-name"><a href="https://adeshpande3.github.io/adeshpande3.github.io/">Adit Deshpande</a></h1>
            <p class="site-description">CS Undergrad at UCLA ('19)</p>
          </div>

          <nav>
            <a href="https://adeshpande3.github.io/adeshpande3.github.io/">Blog</a>
            <a href="https://adeshpande3.github.io/adeshpande3.github.io/about">About</a>
            <a href="https://github.com/adeshpande3">GitHub</a>
            <a href="https://adeshpande3.github.io/adeshpande3.github.io/projects">Projects</a>
            <a href="https://adeshpande3.github.io/adeshpande3.github.io/resume.pdf" target="_blank">Resume</a>
          </nav>
        </header>
      </div>
    </div>

    <div id="main" role="main" class="container">
      <article class="post">
  <h1>A Beginner's Guide To Understanding Convolutional Neural Networks Part 2</h1>

  <div class="entry">
    <link href="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/emoji.css" rel="stylesheet">
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Cover2nd.png">
<h2><p><strong>Introduction</strong></p></h2>
<p><a href="https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks/">Link to Part 1</a>&nbsp;</p>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;In
 this post, we’ll go into a lot more of the specifics of ConvNets. <strong>Disclaimer: </strong>Now,
 I do realize that some of these topics are quite complex and could be 
made in whole posts by themselves. In an effort to remain concise yet 
retain comprehensiveness, I will provide links to research papers where 
the topic is explained in more detail.</p>
<h2><p><strong>Stride and Padding </strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 Alright, let’s look back at our good old conv layers. Remember the 
filters, the receptive fields, the convolving? Good. Now, there are 2 
main parameters that we can change to modify the behavior of each layer.
 After we choose the filter size, we also have to choose the <strong>stride</strong> and the <strong>padding</strong>.</p>
<p>Stride controls how the filter convolves around the input volume. In 
the example we had in part 1, the filter convolves around the input 
volume by shifting one unit at a time. The amount by which the filter 
shifts is the stride. In that case, the stride was implicitly set at 1. 
Stride is normally set in a way so that the output volume is an integer 
and not a fraction. Let’s look at an example. Let’s imagine a 7 x 7 
input volume, a 3 x 3 filter (Disregard the 3<sup>rd</sup> dimension for simplicity), and a stride of 1. This is the case that we’re accustomed to.</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Stride1.png">
<p>Same old, same old, right? See if you can try to guess what will happen to the output volume as the stride increases to 2.</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Stride2.png">
<p>So, as you can see, the receptive field is shifting by 2 units now 
and the output volume shrinks as well. Notice that if we tried to set 
our stride to 3, then we’d have issues with spacing and making sure the 
receptive fields fit on the input volume. Normally, programmers will 
increase the stride if they want receptive fields to overlap less and if
 they want smaller spatial dimensions.</p>
<p>Now, let’s take a look at padding. Before getting into that, let’s 
think about a scenario. What happens when you apply three 5 x 5 x 3 
filters to a 32 x 32 x 3 input volume? The output volume would be 28 x 
28 x 3. Notice that the spatial dimensions decrease. As we keep applying
 conv layers, the size of the volume will decrease faster than we would 
like. In the early layers of our network, we want to preserve as much 
information about the original input volume so that we can extract those
 low level features. Let’s say we want to apply the same conv layer but 
we want the output volume to remain 32 x 32 x 3. To do this, we can 
apply a zero padding of size 2 to that layer. Zero padding pads the 
input volume with zeros around the border. If we think about a zero 
padding of two, then this would result in a 36 x 36 x 3 input volume.</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Pad.png">
<p>If you have a stride of 1 and if you set the size of zero padding to</p>
<p>&nbsp;</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/ZeroPad.png">
<p>where K is the filter size, then the input and output volume will always have the same spatial dimensions.</p>
<p>The formula for calculating the output size for any given conv layer is</p>
<p>&nbsp;</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Output.png">
<p>where O is the output height/length, W is the input height/length, K is the filter size, P is the padding, and S is the stride.</p>
<h2><p><strong>Choosing Hyperparameters</strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 How do we know how many layers to use, how many conv layers, what are 
the filter sizes, or the values for stride and padding? These are not 
trivial questions and there isn’t a set standard that is used by all 
researchers. This is because the network will largely depend on the type
 of data that you have. Data can vary by size, complexity of the image, 
type of image processing task, and more. When looking at your dataset, 
one way to think about how to choose the hyperparameters is to find the 
right combination that creates abstractions of the image at a proper 
scale.</p>
<h2><p><strong>ReLU (Rectified Linear Units) Layers</strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 After each conv layer, it is convention to apply a nonlinear layer (or <strong>activation layer</strong>)
 immediately afterward.The purpose of this layer is to introduce 
nonlinearity to a system that basically has just been computing linear 
operations during the conv layers (just element wise multiplications and
 summations).In the past, nonlinear functions like tanh and sigmoid were
 used, but researchers found out that <strong>ReLU layers</strong> work 
far better because the network is able to train a lot faster (because of
 the computational efficiency) without making a significant difference 
to the accuracy. It also helps to alleviate the vanishing gradient 
problem, which is the issue where the lower layers of the network train 
very slowly because the gradient decreases exponentially through the 
layers (Explaining this might be out of the scope of this post, but see <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">here</a> and <a href="https://www.quora.com/What-is-the-vanishing-gradient-problem">here</a>
 for good descriptions). The ReLU layer applies the function f(x) = 
max(0, x) to all of the values in the input volume. In basic terms, this
 layer just changes all the negative activations to 0.This layer 
increases the nonlinear properties of the model and the overall network 
without affecting the receptive fields of the conv layer.</p>
<p><a href="http://www.cs.toronto.edu/~fritz/absps/reluICML.pdf">Paper</a> by the great Geoffrey Hinton (aka the father of deep learning).</p>
<h2><p><strong>Pooling Layers</strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 After some ReLU layers, programmers may choose to apply a <strong>pooling layer</strong>.
 It is also referred to as a downsampling layer. In this category, there
 are also several layer options, with maxpooling being the most popular.
 This basically takes a filter (normally of size 2x2) and a stride of 
the same length. It then applies it to the input volume and outputs the 
maximum number in every subregion that the filter convolves around.</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/MaxPool.png">
<p>Other options for pooling layers are average pooling and L2-norm 
pooling. The intuitive reasoning behind this layer is that once we know 
that a specific feature is in the original input volume (there will be a
 high activation value), its exact location is not as important as its 
relative location to the other features. As you can imagine, this layer 
drastically reduces the spatial dimension (the length and the width 
change but not the depth) of the input volume. This serves two main 
purposes. The first is that the amount of parameters or weights is 
reduced by 75%, thus lessening the computation cost. The second is that 
it will control <strong>overfitting</strong>. This term refers to when a
 model is so tuned to the training examples that it is not able to 
generalize well for the validation and test sets. A symptom of 
overfitting is having a model that gets 100% or 99% on the training set,
 but only 50% on the test data.</p>
<h2><p><strong>Dropout Layers</strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Now, <strong>dropout layers </strong>have
 a very specific function in neural networks. In the last section, we 
discussed the problem of overfitting, where after training, the weights 
of the network are so tuned to the training examples they are given that
 the network doesn’t perform well when given new examples. The idea of 
dropout is simplistic in nature. This layer “drops out” a random set of 
activations in that layer by setting them to zero. Simple as that. Now, 
what are the benefits of such a simple and seemingly unnecessary and 
counterintuitive process? Well, in a way, it forces the network to be 
redundant. By that I mean the network should be able to provide the 
right classification or output for a specific example even if some of 
the activations are dropped out. It makes sure that the network isn’t 
getting too “fitted” to the training data and thus helps alleviate the 
overfitting problem. An important note is that this layer is only used 
during training, and not during test time.</p>
<p><a href="https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf">Paper</a> by Geoffrey Hinton.</p>
<h2><p><strong>Network in Network Layers</strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; A <strong>network in network</strong>
 layer refers to a conv layer where a 1 x 1 size filter is used. Now, at
 first look, you might wonder why this type of layer would even be 
helpful since receptive fields are normally larger than the space they 
map to. However, we must remember that these 1x1 convolutions span a 
certain depth, so we can think of it as a 1 x 1 x N convolution where N 
is the number of filters applied in the layer. Effectively, this layer 
is performing a N-D element-wise multiplication where N is the depth of 
the input volume into the layer.</p>
<p><a href="https://arxiv.org/pdf/1312.4400v3.pdf">Paper</a> by Min Lin.</p>
<h2><p><strong>Classification, Localization, Detection, Segmentation</strong></p></h2>
<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
 In the example we used in Part 1 of this series, we looked at the task 
of <strong>image classification</strong>. This is the process of taking 
an input image and outputting a class number out of a set of categories.
 However, when we take a task like <strong>object localization</strong>, our job is not only to produce a class label but also a bounding box that describes where the object is in the picture.</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Localization.png">
<p>We also have the task of <strong>object detection</strong>, where 
localization needs to be done on all of the objects in the image. 
Therefore, you will have multiple bounding boxes and multiple class 
labels.</p>
<p>Finally, we also have <strong>object segmentation</strong> where the task is to output a class label as well as an outline of every object in the input image.</p>
<img src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/Detection.png">
<p>More detail on how these are implemented to come in Part 3, but for those who can’t wait…</p>
<p><br> Detection/ Localization: <a href="https://arxiv.org/pdf/1311.2524v5.pdf">RCNN</a>, <a href="https://arxiv.org/pdf/1504.08083.pdf">Fast RCNN</a>, <a href="http://arxiv.org/pdf/1506.01497v3.pdf">Faster RCNN</a>, <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Erhan_Scalable_Object_Detection_2014_CVPR_paper.pdf">MultiBox</a>, <a href="http://web.eecs.umich.edu/~honglak/cvpr15-cnn-detection.pdf">Bayesian Optimization</a>, <a href="http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Gidaris_Object_Detection_via_ICCV_2015_paper.pdf">Multi-region</a>, <a href="http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/lenc15rcnn.pdf">RCNN Minus R</a>, <a href="http://calvin.inf.ed.ac.uk/wp-content/uploads/Publications/alexe12pami.pdf">Image Windows</a><br> Segmentation: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Long_Fully_Convolutional_Networks_2015_CVPR_paper.pdf">Semantic Seg</a>, <a href="http://calvin.inf.ed.ac.uk/wp-content/uploads/Publications/papazoglouICCV2013-camera-ready.pdf">Unconstrained Video</a>, <a href="https://www.cs.cmu.edu/~efros/courses/LBMV07/Papers/Borenstein06.pdf">Shape Guided</a>, <a href="http://crcv.ucf.edu/papers/cvpr2013/VideoObjectSegmentation.pdf">Object Regions</a>, <a href="http://www.cs.utexas.edu/~grauman/papers/shape-sharing-ECCV2012.pdf">Shape Sharing</a></p>
<p>Yeah, there’s a lot more.</p>
<h2><p><strong>Transfer Learning</strong></p></h2>
<p>Now, a common misconception in the DL community is that without a 
Google-esque amount of data, you can’t possibly hope to create effective
 deep learning models. While data is a critical part of creating the 
network, the idea of transfer learning has helped to lessen the data 
demands. <strong>Transfer learning</strong> is the process of taking a 
pre-trained model (the weights and parameters of a network that has been
 trained on a large dataset by somebody else) and “fine-tuning” the 
model with your own dataset. The idea is that this pre-trained model 
will act as a feature extractor. You will remove the last layer of the 
network and replace it with your own classifier (depending on what your 
problem space is). You then freeze the weights of all the other layers 
and train the network normally (Freezing the layers means not changing 
the weights during gradient descent/optimization).</p>
<p>Let’s investigate why this works. Let’s say the pre-trained model 
that we’re talking about was trained on ImageNet (For those that aren’t 
familiar, ImageNet is a dataset that contains 14 million images with 
over 1,000 classes). When we think about the lower layers of the 
network, we know that they will detect features like edges and curves. 
Now, unless you have a very unique problem space and dataset, your 
network is going to need to detect curves and edges as well. Rather than
 training the whole network through a random initialization of weights, 
we can use the weights of the pre-trained model (and freeze them) and 
focus on the more important layers (ones that are higher up) for 
training. If your dataset is quite different than something like 
ImageNet, then you’d want to train more of your layers and freeze only a
 couple of the low layers.</p>
<p><a href="https://arxiv.org/pdf/1411.1792v1.pdf">Paper</a> by Yoshua Bengio (another deep learning pioneer).<br> <a href="http://arxiv.org/pdf/1403.6382.pdf">Paper</a> by Ali Sharif Razavian.<br> <a href="https://arxiv.org/pdf/1310.1531.pdf">Paper</a> by Jeff Donahue.<br> <a href="https://arxiv.org/pdf/1705.07706.pdf">Paper</a> and <a href="https://arxiv.org/pdf/1707.09872.pdf">subsequent paper</a> by Dario Garcia-Gasulla.</p>
<h2><p><strong>Data Augmentation Techniques</strong></p></h2>
<p>By now, we’re all probably numb to the importance of data in 
ConvNets, so let’s talk about ways that you can make your existing 
dataset even larger, just with a couple easy transformations. Like we’ve
 mentioned before, when a computer takes an image as an input, it will 
take in an array of pixel values. Let’s say that the whole image is 
shifted left by 1 pixel. To you and me, this change is imperceptible. 
However, to a computer, this shift can be fairly significant as the 
classification or label of the image doesn’t change, while the array 
does. Approaches that alter the training data in ways that change the 
array representation while keeping the label the same are known as <strong>data augmentation </strong>techniques.
 They are a way to artificially expand your dataset. Some popular 
augmentations people use are grayscales, horizontal flips, vertical 
flips, random crops, color jitters, translations, rotations, and much 
more. By applying just a couple of these transformations to your 
training data, you can easily double or triple the number of training 
examples.</p>
<p style="text-align: left;"><a href="https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html">Link to Part 3</a>&nbsp;</p>
<p>Dueces. <i class="em em-v"></i></p>
<a href="https://adeshpande3.github.io/assets/Sources2.txt" target="_blank"> Sources</a> 
<p></p>
<iframe id="twitter-widget-0" scrolling="no" allowtransparency="true" class="twitter-share-button twitter-share-button-rendered twitter-tweet-button" style="position: static; visibility: visible; width: 60px; height: 20px;" title="Twitter Tweet Button" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/tweet_button.html" frameborder="0"></iframe><script async="" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/widgets.js" charset="utf-8"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-80811190-1', 'auto');
  ga('send', 'pageview');
</script>

  </div>

  <div class="date">
    Written on July 29, 2016
  </div>

  <div id="disqus_thread"><iframe id="dsq-app4832" name="dsq-app4832" allowtransparency="true" scrolling="no" tabindex="0" title="Disqus" style="width: 1px !important; min-width: 100% !important; border: medium none !important; overflow: hidden !important; height: 7860px !important;" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/a.html" horizontalscrolling="no" verticalscrolling="no" width="100%" frameborder="0"></iframe><iframe id="dsq-app4835" name="dsq-app4835" allowtransparency="true" scrolling="no" tabindex="0" title="Disqus" sandbox="allow-forms allow-popups allow-same-origin allow-scripts" style="width: 1px !important; min-width: 100% !important; border: medium none !important; overflow: hidden !important; height: 0px !important; display: none !important;" src="//disqusads.com/ads-iframe/taboola/?category=tech&amp;display_bidding_enabled=0&amp;stories_allowed=1&amp;service=dynamic&amp;position=bottom&amp;display_allowed=1&amp;video_allowed=0&amp;provider=adsnative&amp;thumbnails_allowed=1&amp;experiment=network_default&amp;variant=fallthrough&amp;display_only=0&amp;sandbox_display=1&amp;links_allowed=1&amp;doublewide_allowed=1&amp;shortname=adeshpande3&amp;forum_pk=4419472&amp;forum_shortname=adeshpande3&amp;safetylevel=30&amp;t=1520069449&amp;anchorColor=%234183c4&amp;colorScheme=light&amp;sourceUrl=https%3A%2F%2Fadeshpande3.github.io%2Fadeshpande3.github.io%2FA-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2%2F&amp;typeface=sans-serif&amp;disqus_version=48f16b4" width="100%" hidden="" frameborder="0"></iframe></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'adeshpande3'; // required: replace example with your forum shortname
    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="<a class="vglnk" href="http://disqus.com/?ref_noscript" rel="nofollow"><span>http</span><span>://</span><span>disqus</span><span>.</span><span>com</span><span>/?</span><span>ref</span><span>_</span><span>noscript</span></a>">comments powered by Disqus.</a></noscript>

</article>

    </div>

    <div class="wrapper-footer">
      <div class="container">
        <footer class="footer">
          
<a href="mailto:adeshpande3@g.ucla.edu"><i class="svg-icon email"></i></a>
<a href="https://www.facebook.com/adit.deshpande.5"><i class="svg-icon facebook"></i></a>

<a href="https://github.com/adeshpande3"><i class="svg-icon github"></i></a>
<a href="https://instagram.com/thejugglinguy"><i class="svg-icon instagram"></i></a>
<a href="https://www.linkedin.com/in/aditdeshpande"><i class="svg-icon linkedin"></i></a>

<a href="https://adeshpande3.github.io/adeshpande3.github.io/feed.xml"><i class="svg-icon rss"></i></a>
<a href="https://www.twitter.com/aditdeshpande3"><i class="svg-icon twitter"></i></a>



        </footer>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-80811190-1', 'auto');
		ga('send', 'pageview', {
		  'page': '/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/',
		  'title': 'A Beginner\'s Guide To Understanding Convolutional Neural Networks Part 2'
		});
	</script>
	<!-- End Google Analytics -->


  

<iframe style="display: none;"></iframe><iframe scrolling="no" allowtransparency="true" src="A%20Beginner's%20Guide%20To%20Understanding%20Convolutional%20Neural%20Networks%20Part%202%20%E2%80%93%20Adit%20Deshpande%20%E2%80%93%20CS%20Undergrad%20at%20UCLA%20('19)_files/widget_iframe.html" style="display: none;" frameborder="0"></iframe><iframe id="rufous-sandbox" scrolling="no" allowtransparency="true" allowfullscreen="true" style="position: absolute; visibility: hidden; display: none; width: 0px; height: 0px; padding: 0px; border: medium none;" title="Twitter analytics iframe" frameborder="0"></iframe></body></html>