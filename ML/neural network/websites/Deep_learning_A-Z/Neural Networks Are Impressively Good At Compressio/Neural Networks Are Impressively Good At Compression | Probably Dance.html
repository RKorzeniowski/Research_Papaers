<!DOCTYPE html>
<!--[if IE 6]>
<html id="ie6" lang="en">
<![endif]-->
<!--[if IE 7]>
<html id="ie7" lang="en">
<![endif]-->
<!--[if IE 8]>
<html id="ie8" lang="en">
<![endif]-->
<!--[if !(IE 6) & !(IE 7) & !(IE 8)]><!-->
<html class="gr__probablydance_com" lang="en"><!--<![endif]--><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
	<meta charset="UTF-8">
	<title>Neural Networks Are Impressively Good At Compression | Probably Dance</title>

	<link rel="pingback" href="https://probablydance.com/xmlrpc.php">
	<!--[if lt IE 9]>
		<script src="https://s0.wp.com/wp-content/themes/pub/manifest/js/html5.js" type="text/javascript"></script>
	<![endif]-->

			<script src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/remote-login.php" type="text/javascript"></script>
		<script type="text/javascript">
		/* <![CDATA[ */
			if ( 'function' === typeof WPRemoteLogin ) {
				document.cookie = "wordpress_test_cookie=test; path=/";
				if ( document.cookie.match( /(;|^)\s*wordpress_test_cookie\=/ ) ) {
					WPRemoteLogin();
				}
			}
		/* ]]> */
		</script>
		<link rel="dns-prefetch" href="https://s2.wp.com/">
<link rel="dns-prefetch" href="https://s1.wp.com/">
<link rel="dns-prefetch" href="https://s0.wp.com/">
<link rel="dns-prefetch" href="https://probablydance.wordpress.com/">
<link rel="alternate" type="application/rss+xml" title="Probably Dance » Feed" href="https://probablydance.com/feed/">
<link rel="alternate" type="application/rss+xml" title="Probably Dance » Comments Feed" href="https://probablydance.com/comments/feed/">
<link rel="alternate" type="application/rss+xml" title="Probably Dance » Neural Networks Are Impressively Good At&nbsp;Compression Comments Feed" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/feed/">
	<script type="text/javascript">
		/* <![CDATA[ */
		function addLoadEvent(func) {
			var oldonload = window.onload;
			if (typeof window.onload != 'function') {
				window.onload = func;
			} else {
				window.onload = function () {
					oldonload();
					func();
				}
			}
		}
		/* ]]> */
	</script>
			<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/72x72\/","ext":".png","svgUrl":"https:\/\/s0.wp.com\/wp-content\/mu-plugins\/wpcom-smileys\/twemoji\/2\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/s1.wp.com\/wp-includes\/js\/wp-emoji-release.min.js?m=1516999477h&ver=4.9.4"}};
			!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline="top",l.font="600 32px Arial",a){case"flag":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case"emoji":return b=d([55357,56692,8205,9792,65039],[55357,56692,8203,9792,65039]),!b}return!1}function f(a){var c=b.createElement("script");c.src=a,c.defer=c.type="text/javascript",b.getElementsByTagName("head")[0].appendChild(c)}var g,h,i,j,k=b.createElement("canvas"),l=k.getContext&&k.getContext("2d");for(j=Array("flag","emoji"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],"flag"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener("DOMContentLoaded",h,!1),a.addEventListener("load",h,!1)):(a.attachEvent("onload",h),b.attachEvent("onreadystatechange",function(){"complete"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);
		</script><script src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/wp-emoji-release.js" type="text/javascript" defer="defer"></script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
<link rel="stylesheet" id="all-css-0-1" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a_004.css" type="text/css" media="all">
<!--[if IE 7]>
<link rel='stylesheet' id='manifest-ie-css'  href='https://s0.wp.com/wp-content/themes/pub/manifest/css/style_ie.css?ver=4.9.4' type='text/css' media='all' />
<![endif]-->
<link rel="stylesheet" id="all-css-2-1" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a_002.css" type="text/css" media="all">
<link rel="stylesheet" id="print-css-3-1" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/global-print.css" type="text/css" media="print">
<link rel="stylesheet" id="all-css-4-1" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a.css" type="text/css" media="all">
<script type="text/javascript">
/* <![CDATA[ */
var related_posts_js_options = {"post_heading":"h4"};
/* ]]> */
</script>
<script type="text/javascript" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a"></script>
<link rel="stylesheet" id="all-css-0-2" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/style.css" type="text/css" media="all">
<!--[if lt IE 8]>
<link rel='stylesheet' id='highlander-comments-ie7-css'  href='https://s1.wp.com/wp-content/mu-plugins/highlander-comments/style-ie7.css?m=1351637563h&#038;ver=20110606' type='text/css' media='all' />
<![endif]-->
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://probablydance.wordpress.com/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://s1.wp.com/wp-includes/wlwmanifest.xml"> 
<link rel="prev" title="VR Will Be About Using Your&nbsp;Hands" href="https://probablydance.com/2016/03/25/vr-will-be-about-using-your-hands/">
<link rel="next" title="C++11 Completed RAII, Making Composition&nbsp;Easier" href="https://probablydance.com/2016/06/03/c11-completed-raii-making-composition-easier/">
<meta name="generator" content="WordPress.com">
<link rel="canonical" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/">
<link rel="shortlink" href="https://wp.me/p1xYfp-Dh">
<link rel="alternate" type="application/json+oembed" href="https://public-api.wordpress.com/oembed/?format=json&amp;url=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&amp;for=wpcom-auto-discovery"><link rel="alternate" type="application/xml+oembed" href="https://public-api.wordpress.com/oembed/?format=xml&amp;url=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F&amp;for=wpcom-auto-discovery">
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article">
<meta property="og:title" content="Neural Networks Are Impressively Good At Compression">
<meta property="og:url" content="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/">
<meta property="og:description" content="I’m trying to get into neural networks. There have been a couple big breakthroughs in the field in recent years and suddenly my side project of messing around with programming languages seeme…">
<meta property="article:published_time" content="2016-04-30T13:24:10+00:00">
<meta property="article:modified_time" content="2016-04-30T13:33:09+00:00">
<meta property="og:site_name" content="Probably Dance">
<meta property="og:image" content="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png">
<meta property="og:image:width" content="423">
<meta property="og:image:height" content="308">
<meta property="og:locale" content="en_US">
<meta name="twitter:site" content="@wordpressdotcom">
<meta name="twitter:text:title" content="Neural Networks Are Impressively Good At&nbsp;Compression">
<meta name="twitter:image" content="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=240">
<meta name="twitter:card" content="summary">
<meta property="article:publisher" content="https://www.facebook.com/WordPresscom">
<link rel="shortcut icon" type="image/x-icon" href="https://s2.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48">
<link rel="icon" type="image/x-icon" href="https://s2.wp.com/i/favicon.ico" sizes="16x16 24x24 32x32 48x48">
<link rel="apple-touch-icon-precomposed" href="https://s0.wp.com/i/webclip.png">
<link rel="openid.server" href="https://probablydance.wordpress.com/?openidserver=1">
<link rel="openid.delegate" href="https://probablydance.wordpress.com/">
<link rel="search" type="application/opensearchdescription+xml" href="https://probablydance.com/osd.xml" title="Probably Dance">
<link rel="search" type="application/opensearchdescription+xml" href="https://s1.wp.com/opensearch.xml" title="WordPress.com">
<meta name="application-name" content="Probably Dance"><meta name="msapplication-window" content="width=device-width;height=device-height"><meta name="msapplication-tooltip" content="I can program and like games"><meta name="msapplication-task" content="name=Subscribe;action-uri=https://probablydance.com/feed/;icon-uri=https://s2.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=https://s2.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=https://s2.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=https://s2.wp.com/i/favicon.ico"><meta name="title" content="Neural Networks Are Impressively Good At&nbsp;Compression | Probably Dance on WordPress.com">
<meta name="description" content="I'm trying to get into neural networks. There have been a couple big breakthroughs in the field in recent years and suddenly my side project of messing around with programming languages seemed short sighted. It almost seems like we'll have real AI soon and I want to be working on that. While making my first…">
<link rel="amphtml" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/amp/"><style type="text/css" id="syntaxhighlighteranchor"></style>
<style type="text/css" id="custom-colors-css">#site-wrapper{border-style:solid;border-width:0 2px;padding:15px 120px}#footer{border-left:2px solid;border-right:2px solid;margin-top:0;padding:30px 120px}#wpstats{margin-bottom:0;margin-top:-10px}#footer{border-top-color:#000}#footer{border-top-color:rgba(0,0,0,.1)}#infinite-handle span{background-color:#333}#site-wrapper{background-color:#fff}#footer{background-color:#fff}input[type=submit],#core-content #respond #comment-submit{color:#000}#infinite-handle span{color:#000}#infinite-handle span::before{color:#fff}#infinite-handle span::before{color:rgba(255,255,255,.4)}body{background-color:#fff}body{background-color:rgba(255,255,255,.2)}#site-wrapper{border-color:#fff}#footer{border-left-color:#fff}#footer{border-right-color:#fff}h1 a:link,h1 a:visited,h1 a:hover,h1 a:active{color:#648285}input[type=submit],#core-content #respond #comment-submit{background-color:#8ea7aa}input[type=submit],#core-content #respond #comment-submit{background:#697d80}input[type=submit],#core-content #respond #comment-submit{border-color:#526264}input[type=submit]:hover,input[type=submit]:focus,#core-content #respond #comment-submit:hover{background-color:#526264}a:link,a:visited{color:#7a6c51}h5.post-date{border-bottom-color:#9c8a6a}h5.post-date{border-bottom-color:rgba(156,138,106,.8)}.format-status .post-content{background-color:#9c8a6a}.format-status .post-content{background-color:rgba(156,138,106,.05)}html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{border-color:#000}h3 a:link,h3 a:visited,h2,.entry-content strong,h2.archive-title strong{color:#000}</style>
		<link rel="stylesheet" id="custom-css-css" type="text/css" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a_003.css">
		<style type="text/css"></style><link rel="stylesheet" type="text/css" id="gravatar-card-css" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/hovercard.css"><link rel="stylesheet" type="text/css" id="gravatar-card-services-css" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/services.css"></head>

<body class="post-template-default single single-post postid-2435 single-format-standard mp6 customizer-styles-applied highlander-enabled highlander-light custom-colors" data-gr-c-s-loaded="true">

<div id="site-wrapper">
	<h1 class="vcard author" id="site-title"><a href="https://probablydance.com/" title="Home" class="fn">Probably Dance</a></h1>
	<nav id="main-nav">
			<ul>
			</ul>
	</nav>
		<div id="site-description">
		I can program and like games	</div>

<div id="core-content">


	
<div class="post-2435 post type-post status-publish format-standard hentry category-programming tag-ai tag-neural-networks" id="post-2435">
	<div class="post-content">
		<h3 class="entry-title">Neural Networks Are Impressively Good At&nbsp;Compression</h3>		<h4 class="vcard author">by <span class="fn">Malte Skarupke</span></h4>

				<div class="entry-content">
			<p>I’m trying to get into neural networks. There have been a couple 
big breakthroughs in the field in recent years and suddenly my side 
project of messing around with programming languages seemed short 
sighted. It almost seems like we’ll have real AI soon and I want to be 
working on that. While making my first couple steps into the field it’s 
hard to keep that enthusiasm. A lot of the field is still kinda handwavy
 where when you want to find out why something is used the way it’s 
used, the only answer you can get is “because it works like this and it 
doesn’t work if we change it.”</p>
<p>At least that’s my first impression. Still just dipping my toes in. 
But there is one thing I am very impressed with: How much data neural 
networks can express in how few connections.</p>
<p><span id="more-2435"></span></p>
<p>To illustrate let me draw a very simple neural network. It’s not a 
very interesting neural network, I’m just connecting inputs to outputs:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png"><img data-attachment-id="2441" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/1_fully_connected/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=650" data-orig-size="421,307" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1_fully_connected" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=650?w=421" class="alignnone size-full wp-image-2441" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/1_fully_connected.png" alt="1_fully_connected" srcset="https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png 421w, https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/1_fully_connected.png?w=300 300w" sizes="(max-width: 421px) 100vw, 421px"></a></p>
<p>And now let’s say that I want to teach this neural network the 
following pattern: Whenever input 1 fires, fire output 2. When input 2 
fires, fire output 3. When input 3 fires, fire output 4. When input 4 
fires, fire output 5. Output 1 never gets fired and input 5 never gets 
fired. To do that you use an algorithm called back propagation and 
repeatedly tell the network what output you expect for a given input, 
but that is not what I want to talk about here. I want to talk about the
 results. I’ll make the connections that the network learns stronger, 
and the connections that the network doesn’t learn weaker:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/2_learned.png"><img data-attachment-id="2442" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/2_learned/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=650" data-orig-size="422,301" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2_learned" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=650?w=422" class="alignnone size-full wp-image-2442" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/2_learned.png" alt="2_learned" srcset="https://probablydance.files.wordpress.com/2016/04/2_learned.png 422w, https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/2_learned.png?w=300 300w" sizes="(max-width: 422px) 100vw, 422px"></a></p>
<p>What happened here is that the weights for some connections have 
increased, while the weights for most connections have decreased. I 
haven’t talked about weights yet. Weights are what neural networks 
learn. When we draw networks, the nodes seem more important. But what 
the network actually learns and stores are weights on the connections. 
In the picture above the thick lines have a weight of 1, the others have
 a weight of 0. (weights can also go negative, and they can go up 
arbitrarily high)</p>
<h2>Hidden Layers</h2>
<p>A simple network like the one above can learn simple patterns like 
this. If we want to learn more complex patterns, we have to create a 
network that has more layers. Let’s insert a layer with two neurons in 
the middle:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png"><img data-attachment-id="2443" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/3_middle_layer/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=650" data-orig-size="421,303" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="3_middle_layer" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=650?w=421" class="alignnone size-full wp-image-2443" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/3_middle_layer.png" alt="3_middle_layer" srcset="https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png 421w, https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/3_middle_layer.png?w=300 300w" sizes="(max-width: 421px) 100vw, 421px"></a></p>
<p>There are many possible behaviors for those neurons in the middle, 
and that is the part where most of the magic happens in neural networks.
 It seems like picking what goes there just requires experimentation and
 experience. A simple neuron would be the tanh neuron which does these 
three steps:</p>
<ol>
<li>add up all of its inputs multiplied by their weights</li>
<li>calculate tanh() on the sum</li>
<li>fire the result to its outputs multiplied by their weights</li>
</ol>
<p>Why tanh? Because it has a couple convenient properties, and it 
happens to work better than other functions that have the same 
properties. But mostly it’s “beause it works like this and it doesn’t 
work when we change it.”</p>
<p>If you count the number of connections on that last picture you will 
notice that there are fewer than there were in the first network. There 
were 5*5=25 at first, now there are 5*2*2=20. That reduction would be 
larger if I had more input and output nodes. For 10 nodes that reduction
 would be from 100 connections down to 40 when inserting two nodes in 
the middle. That’s where the compression in the title of this blog post 
comes from.</p>
<p>The question is whether we can still represent the original pattern 
in this new representation. To show why that is not obvious, I’ll 
explain why it doesn’t work if you just have one middle neuron:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png"><img data-attachment-id="2444" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/4_single_middle/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=650" data-orig-size="414,299" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="4_single_middle" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=650?w=414" class="alignnone size-full wp-image-2444" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/4_single_middle.png" alt="4_single_middle" srcset="https://probablydance.files.wordpress.com/2016/04/4_single_middle.png 414w, https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/4_single_middle.png?w=300 300w" sizes="(max-width: 414px) 100vw, 414px"></a></p>
<p>If I initialize the weights on here so that the first node fires the second output, all nodes will fire the second output:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png"><img data-attachment-id="2445" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/5_single_middle_weights/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=650" data-orig-size="416,299" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="5_single_middle_weights" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=650?w=416" class="alignnone size-full wp-image-2445" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/5_single_middle_weights.png" alt="5_single_middle_weights" srcset="https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png 416w, https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/5_single_middle_weights.png?w=300 300w" sizes="(max-width: 416px) 100vw, 416px"></a></p>
<p>That one node in the middle messes up the ability for my network to 
learn my very simple rule. This network can not learn different 
behaviors for different input nodes because they all have to go through 
that one node in the middle. Remember that the node in the middle just 
adds all of its inputs, so it can not have different behaviors depending
 on which input it receives. The information of where a value came from 
gets lost in the summation.</p>
<p>So how many nodes do I need to put into the middle to still be able 
to learn my rule? In real neural networks you usually put hundreds of 
nodes into that middle layer, but what is the minimal number to learn my
 pattern? Before I get to the answer I need to explain one more type of 
neuron that enables my compression: The softmax layer. If I make my 
output layer a softmax layer, that means that it will look at all the 
activations on that layer, and that it will only fire the output with 
the highest activation. That’s where the “max” in the softmax comes 
from: It fires the max node. The “soft” part is also very important in 
other contexts because a softmax layer can fire more than one output, 
but in my case it will only ever fire one output so we’ll stay with this
 explanation. If I make my middle layer a tanh layer and my output layer
 a softmax layer, I can represent my pattern just by having two nodes in
 the middle:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/6_learned1.png"><img data-attachment-id="2464" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/6_learned-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=650" data-orig-size="415,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="6_learned" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=650?w=415" class="alignnone size-full wp-image-2464" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/6_learned1.png" alt="6_learned" srcset="https://probablydance.files.wordpress.com/2016/04/6_learned1.png 415w, https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/6_learned1.png?w=300 300w" sizes="(max-width: 415px) 100vw, 415px"></a></p>
<p>Here I’ve made lines with positive weights blue, and lines with 
negative weights red. This means that if for example the first input 
fires, I will get these values on the nodes:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png"><img data-attachment-id="2465" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/7_learned_first_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=650" data-orig-size="413,303" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="7_learned_first_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=650?w=413" class="alignnone size-full wp-image-2465" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/7_learned_first_input1.png" alt="7_learned_first_input" srcset="https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png 413w, https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/7_learned_first_input1.png?w=300 300w" sizes="(max-width: 413px) 100vw, 413px"></a></p>
<p>The first node activates both the middle nodes. That activates the 
second output node with weight two. The next two nodes are canceled out 
because they receive a positive weight from one of the middle nodes and a
 negative weight from the other. The last node is activated with weight 
-2. If I then run softmax on this only the top node will fire. Meaning 
the bottom node will not fire a negative output. Softmax suppresses 
everything except for the most active node.</p>
<p>This is a little bit simplified, because the tanh layer doesn’t give 
out nice round numbers and the softmax layer wants bigger numbers, but 
those complications are not necessary to understand what’s going on, so 
I’ll keep the numbers in this blog post simple. (the real weights in my 
test code are +9 and -9 on the connections going from the input layer to
 the middle layer, and +26 and -26 on the connections going from the 
middle layer to the output layer. I don’t know why those numbers 
specifically, that’s just where the network decided to stabilize)</p>
<p>Let’s quickly run through this for the other three cases as well:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png"><img data-attachment-id="2466" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/8_learned_second_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=650" data-orig-size="417,311" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="8_learned_second_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=650?w=417" class="alignnone size-full wp-image-2466" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/8_learned_second_input1.png" alt="8_learned_second_input" srcset="https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png 417w, https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/8_learned_second_input1.png?w=300 300w" sizes="(max-width: 417px) 100vw, 417px"></a></p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png"><img data-attachment-id="2467" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/9_learned_third_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=650" data-orig-size="419,309" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="9_learned_third_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=650?w=419" class="alignnone size-full wp-image-2467" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/9_learned_third_input1.png" alt="9_learned_third_input" srcset="https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png 419w, https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/9_learned_third_input1.png?w=300 300w" sizes="(max-width: 419px) 100vw, 419px"></a></p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png"><img data-attachment-id="2468" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/10_learned_last_input-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=650" data-orig-size="423,308" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="10_learned_last_input" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=650?w=423" class="alignnone size-full wp-image-2468" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/10_learned_last_input1.png" alt="10_learned_last_input" srcset="https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png 423w, https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=150 150w, https://probablydance.files.wordpress.com/2016/04/10_learned_last_input1.png?w=300 300w" sizes="(max-width: 423px) 100vw, 423px"></a></p>
<p>As you can see there is always one clear winner and then the softmax 
layer at the end will make sure that only that one fires and the other 
outputs remain quiet. When I first saw this behavior I was quite 
impressed. In fact I saw this behavior on a network with eleven inputs, 
eleven outputs and just two middle nodes. Can you think of how the above
 layer would work with eleven inputs? It seems like there’s only four 
possible combinations for these weights and we’ve used all of them, 
right? You’re underestimating neural networks. It’s quite impressive how
 they will try to squeeze any pattern that you throw at them into what’s
 available. For eleven inputs and eleven outputs it looks like this:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png"><img data-attachment-id="2473" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/14_eleven_numbers-2/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=650" data-orig-size="500,793" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="14_eleven_numbers" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=650?w=189" data-large-file="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=650?w=500" class="alignnone size-full wp-image-2473" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/14_eleven_numbers1.png" alt="14_eleven_numbers" srcset="https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png 500w, https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=95 95w, https://probablydance.files.wordpress.com/2016/04/14_eleven_numbers1.png?w=189 189w" sizes="(max-width: 500px) 100vw, 500px"></a></p>
<p>That is a lot of connections and a lot of numbers. The network has 
now decided to make some connections stronger and other connections 
weaker. I couldn’t keep using colors and line-style to visualize 
different strengths because now there are a lot of different values. 
Whenever I tried to simplify and not use numbers I’d break the network. 
So instead I just show the numbers. The upper number on each node is the
 weight of the connection to/from the upper node in the middle layer, 
and the lower number is the weight of the connection to/from the lower 
node in the middle layer.</p>
<p>Let’s walk through a random example and see how it works:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png"><img data-attachment-id="2474" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/15_eleven_numbers_example/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=650" data-orig-size="507,799" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="15_eleven_numbers_example" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=650?w=190" data-large-file="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=650?w=507" class="alignnone size-full wp-image-2474" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/15_eleven_numbers_example.png" alt="15_eleven_numbers_example" srcset="https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png 507w, https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=95 95w, https://probablydance.files.wordpress.com/2016/04/15_eleven_numbers_example.png?w=190 190w" sizes="(max-width: 507px) 100vw, 507px"></a></p>
<p>The node with the largest output value (72 = -10 * -4 + 8 * 4) is the
 one we want to fire, and softmax will select that. In this picture I’m 
just multiplying the numbers linearly because the weights on the left 
actually already have tanh applied (and were then multiplied by 10 to 
get them into the range -10 to 10 which is slightly nicer for pictures 
than the range -1 to 1). I can do that in this case since I only ever 
fire one input. And if I can just do linear math the example is easier 
to follow.</p>
<p>I’ll post a second example to show that the weights will activate the desired output for any input:</p>
<p><a href="https://probablydance.files.wordpress.com/2016/04/16_second_example.png"><img data-attachment-id="2475" data-permalink="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/16_second_example/" data-orig-file="https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=650" data-orig-size="496,790" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="16_second_example" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=650?w=188" data-large-file="https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=650?w=496" class="alignnone size-full wp-image-2475" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/16_second_example.png" alt="16_second_example" srcset="https://probablydance.files.wordpress.com/2016/04/16_second_example.png 496w, https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=94 94w, https://probablydance.files.wordpress.com/2016/04/16_second_example.png?w=188 188w" sizes="(max-width: 496px) 100vw, 496px"></a></p>
<p>Here also for my given input n, output n+1 had the highest value at 
the end and softmax will make that output fire. You could go through a 
couple more examples and convince yourself that this network has learned
 the pattern that I want it to learn.</p>
<p>I don’t know about you, but I think this is quite impressive. For the
 small first network I think I could have figured out how to put the 
numbers in manually. (once you know the trick that the nodes can cancel 
each other out it’s easy) For all the connections on the larger network 
you would have to be very good at balancing these weights, and I 
honestly don’t think I could have done this by hand. The neural network 
however seems to just figure this out. Or rather: it figures this out if
 you use a tanh layer in the middle and a softmax layer at the end. If 
you don’t, it will stop working.</p>
<p>Since I’m using real numbers now I might as well explain how softmax 
works. Softmax uses the number at the end as an exponent and then 
normalizes the column afterwards. If I use 2^x it should be obvious that
 2^56, the highest number, is a lot bigger than 2^44, the next highest 
number. If I have 2^56 in the column and I normalize it, all the other 
activations will go very close to zero and the output that I want to 
fire will be close to 1. Also by using an exponent I get no negative 
numbers. 2^-96 is just a number that’s very close to zero. The standard 
is to use e^x instead of 2^x, and I also use that, it’s just that as a 
programmer I find it easier to explain and easier to understand using 
powers of two.</p>
<h2>How This Works</h2>
<p>With that information I can give a bit of an intuition why this 
happens to work if you use tanh and softmax: When using softmax, the 
connections can keep on improving the chance of their desired output 
just by making their own weights bigger. In fact since I just used 
linear math in my explanation above and didn’t need to run tanh() on 
anything, couldn’t softmax have learned those weighs even without using a
 tanh layer? In theory it could, but in practice it will keep on bumping
 up the numbers to get small improvements and you will very quickly 
overflow floating point numbers. The tanh layer in the middle is then 
just responsible for keeping the numbers small: it clamps its outputs to
 the range -1 to 1, and the inputs won’t grow past a certain point 
either because at some point a bigger number just means that the output 
goes from 0.995 to 0.997. But since they can usually still get a small 
improvement you don’t lose that nice property of softmax where neurons 
can keep on edging out small improvements over each other.</p>
<p>So if you just use softmax your weights will explode and if you just 
use tanh your weights will stagnate too soon before a good solution 
emerges. If you use both you get nice greedy behavior where the 
connections keep on looking for better solutions, but you also keep the 
weights from exploding.</p>
<p>Now all I’ve shown is that my network can learn the rule that when 
input n fires, it needs to fire output n+1. It should be easy to see 
that just by creating a different permutation of the weights of the 
connections I can teach my network that for any input neuron x, it 
should fire any other output neuron y. The impressive part is that 
without the middle layer I would have needed 11*11 = 121 connections to 
have a network that can learn any combination, and with that middle 
layer I can do it in only 11*2*2 = 44 connections.</p>
<p>Eleven inputs and outputs is close to the limit for what you can do 
with two nodes in the middle. If you ask it to do much more the weights 
will fluctuate and they will keep on stepping on each others toes. But 
with three nodes in the middle I can learn these patterns for something 
like thirty inputs and outputs, and with four nodes, I can learn direct 
connections for more than a hundred inputs and outputs. It doesn’t grow 
linearly because the number of combinations doesn’t grow linearly. 
Luckily the back propagation algorithm scales with the number of 
connections, not with the number of combinations. So with a linear 
increase in computation cost I get a super-linear increase in the amount
 of stuff I can learn.</p>
<h2>Outlook and Conclusions</h2>
<p>I’m still just getting started with neural networks, and real 
networks look nothing like my tiny examples above. I don’t know how many
 neurons people actually use nowadays, but even small examples talk 
about hundreds of neurons. At that point it’s more difficult to 
understand what your network has learned. You can’t visualize it as 
easily as the above pictures. In fact even the eleven neuron picture is 
difficult to understand because you can’t just look at the strong 
connections. Even the weak connections are important. If that middle 
layer had 700 neurons, then good luck getting a picture of which 
connections are actually important. Maybe a bunch of weak connections 
add up to build the output you wanted and one random strong connection 
suppresses all the unwanted outputs that you didn’t want.</p>
<p>But I hope I have given you an intuition for how neural networks can 
compress patterns in few weights. They use the full range of the weights
 to the point where a connection activated with a strong input can mean 
something entirely different than the same connection activated with a 
weak input. And best of all I didn’t have to teach them to do this. They
 just start behaving like this if you force them to express a complex 
pattern in few connections.</p>
<div id="jp-post-flair" class="sharedaddy sd-like-enabled sd-sharing-enabled"><div class="sharedaddy sd-sharing-enabled"><div class="robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing"><h3 class="sd-title">Share this:</h3><div class="sd-content"><ul><li class="share-twitter"><a rel="nofollow" data-shared="sharing-twitter-2435" class="share-twitter sd-button share-icon" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?share=twitter&amp;nb=1" target="_blank" title="Click to share on Twitter"><span>Twitter</span></a></li><li class="share-facebook"><a rel="nofollow" data-shared="sharing-facebook-2435" class="share-facebook sd-button share-icon" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?share=facebook&amp;nb=1" target="_blank" title="Share on Facebook"><span>Facebook<span class="share-count">197</span></span></a></li><li class="share-end"></li></ul></div></div></div><div class="sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-loaded" id="like-post-wrapper-22872755-2435-5a9a71042b069" data-src="//widgets.wp.com/likes/index.html?ver=20180228#blog_id=22872755&amp;post_id=2435&amp;origin=probablydance.wordpress.com&amp;obj_id=22872755-2435-5a9a71042b069" data-name="like-post-frame-22872755-2435-5a9a71042b069"><h3 class="sd-title">Like this:</h3><div class="likes-widget-placeholder post-likes-widget-placeholder" style="height: 55px;"><span class="button"><span>Like</span></span> <span class="loading">Loading...</span></div><iframe class="post-likes-widget jetpack-likes-widget" name="like-post-frame-22872755-2435-5a9a71042b069" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/index.html" width="100%" height="55px" frameborder="0"></iframe><span class="sd-text-color"></span><a class="sd-link-color"></a></div>
<div id="jp-relatedposts" class="jp-relatedposts" style="display: block;">
	<h3 class="jp-relatedposts-headline"><em>Related</em></h3>
<div class="jp-relatedposts-items jp-relatedposts-items-minimal"><p class="jp-relatedposts-post jp-relatedposts-post0" data-post-id="2311" data-post-format="false"><span class="jp-relatedposts-post-title"><a class="jp-relatedposts-post-a" href="https://probablydance.com/2016/02/27/functional-programming-is-not-popular-because-it-is-weird/" title="Functional Programming Is Not Popular Because It Is Weird

I've seen people be genuinely puzzled about why functional programming is not more popular. For example I'm currently reading &quot;Out of the Tar Pit&quot; where after arguing for functional programming the authors say Still, the fact remains that such arguments have been insufficient to result in widespread adoption of functional…" rel="nofollow" data-origin="2435" data-position="0">Functional Programming Is Not Popular Because It Is Weird</a></span><span class="jp-relatedposts-post-context">In "Programming"</span></p><p class="jp-relatedposts-post jp-relatedposts-post1" data-post-id="6655" data-post-format="false"><span class="jp-relatedposts-post-title"><a class="jp-relatedposts-post-a" href="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/" title="I Wrote The Fastest Hashtable

I had to get there eventually. I had a blog post called &quot;I Wrote a Fast Hashtable&quot; and another blog post called &quot;I Wrote a Faster Hashtable.&quot; Now I finally wrote the fastest hashtable. And by that I mean that I have the fastest lookups of any hashtable I could…" rel="nofollow" data-origin="2435" data-position="1">I Wrote The Fastest Hashtable</a></span><span class="jp-relatedposts-post-context">In "Programming"</span></p><p class="jp-relatedposts-post jp-relatedposts-post2" data-post-id="4987" data-post-format="false"><span class="jp-relatedposts-post-title"><a class="jp-relatedposts-post-a" href="https://probablydance.com/2016/12/27/i-wrote-a-faster-sorting-algorithm/" title="I Wrote a Faster Sorting Algorithm

These days it's a pretty bold claim if you say that you invented a sorting algorithm that's 30% faster than state of the art. Unfortunately I have to make a far bolder claim: I wrote a sorting algorithm that's twice as fast as std::sort for many inputs. And except when…" rel="nofollow" data-origin="2435" data-position="2">I Wrote a Faster Sorting Algorithm</a></span><span class="jp-relatedposts-post-context">In "Programming"</span></p></div></div></div>					</div>
	</div>
	<div class="post-meta">
						<div class="post-date"><span>Published:</span> <abbr class="published" title="2016-04-30T06:24:10-0800"><a href="https://probablydance.com/2016/04/30/">April 30, 2016</a></abbr></div>
		<div class="categories"><span>Filed Under:</span> <a href="https://probablydance.com/category/programming/" rel="category tag">Programming</a></div>
		<span>Tags:</span> <a href="https://probablydance.com/tag/ai/" rel="tag">ai</a> : <a href="https://probablydance.com/tag/neural-networks/" rel="tag">neural networks</a>	</div>
</div>
	<div id="comments">
	
			<h3 id="comments">16 Comments to “Neural Networks Are Impressively Good At&nbsp;Compression”</h3>

		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"></div>
		</div>

		<ol class="commentlist">
				<li class="comment byuser comment-author-graphific even thread-even depth-1 parent highlander-comment" id="comment-2695">
				<div id="div-comment-2695" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/866ac17d713ed49c713e14e9b4ba34ab.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-866ac17d713ed49c713e14e9b4ba34ab-0" width="48" height="48">			<cite class="fn"><a href="http://gravatar.com/graphific" rel="external nofollow" class="url">graphific</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2695">
			April 30, 2016 at 10:21</a>		</div>

		<p>congratulations, not sure if you heard of Auto-Encoders before, but
 thats essentially what you have been constructing. nice! See ie <a href="http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/" rel="nofollow">http://ufldl.stanford.edu/tutorial/unsupervised/Autoencoders/</a></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2695#respond" onclick='return addComment.moveForm( "div-comment-2695", "2695", "respond", "2435" )' aria-label="Reply to graphific">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor odd alt depth-2 highlander-comment" id="comment-2703">
				<div id="div-comment-2703" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-32d3ef171bc897317c4a77a83f44fbcb-0" width="48" height="48">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2703">
			May 1, 2016 at 10:48</a>		</div>

		<p>Thanks! That is indeed exactly what I’ve been constructing. I’m 
still new to the field and was just playing around with neurons to get a
 better understanding for them, so it doesn’t surprise me that this is a
 known thing.</p>
<p>It’s weird how you can miss things that are blindingly obvious in 
hindsight. Like when I talked about permutations above I should have 
realized that I can just make the network learn to always make the 
output equal to the input. And then I can get all other patterns just by
 creating a permutation of the weights. That’s what auto encoders do and
 that would have been a simpler problem to solve and to explain, and it 
would have given me the same solution.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2703#respond" onclick='return addComment.moveForm( "div-comment-2703", "2703", "respond", "2435" )' aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2696">
				<div id="div-comment-2696" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/e214f5c143b40458c473bef6ee05823e.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-e214f5c143b40458c473bef6ee05823e-0" width="48" height="48">			<cite class="fn">Martin Cohen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2696">
			April 30, 2016 at 16:14</a>		</div>

		<p>I don’t know if this is relevant, but the logistic curve (which is a
 scaled and shifted tanh) and the normal cdf are fairly close, differing
 by at most 0.044. If the logistic curve is modified so that its slope 
match the normal cdf at zero, the difference is at most 0.017. I wonder 
how the results using a shifted normal cdf would differ from the tanh 
you use.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2696#respond" onclick='return addComment.moveForm( "div-comment-2696", "2696", "respond", "2435" )' aria-label="Reply to Martin Cohen">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor odd alt depth-2 parent highlander-comment" id="comment-2704">
				<div id="div-comment-2704" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-32d3ef171bc897317c4a77a83f44fbcb-1" width="48" height="48">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2704">
			May 1, 2016 at 11:11</a>		</div>

		<p>A lot of different activation functions have been tried and wikipedia has a good list of them:<br>
<a href="https://en.wikipedia.org/wiki/Activation_function" rel="nofollow">https://en.wikipedia.org/wiki/Activation_function</a></p>
<p>The ones you mentioned are in there, but I don’t know why they’re not used more often.</p>
<p>Google has a great website where you can play around with neural 
networks, and one of the parameters on there is the activation function:<br>
<a href="http://playground.tensorflow.org/" rel="nofollow">http://playground.tensorflow.org</a></p>
<p>You can try Tanh, Sigmoid (which I think is what you mean when you 
say logistic curve) and ReLU activation functions. For the initial setup
 and the initial problem on the website if I select Tanh, the network 
arrives at a solution in something like 50 iterations. Using Sigmoid I 
get an approximate solution and even after more than 5000 iterations I 
don’t get the right solution. Trying a second time with a new random 
starting position it did arrive at a correct solution but took 900 
iterations to get there. ReLU solves the problem in something like 30 
iterations.</p>
<p>I don’t know why Sigmoid should be so very bad at that problem. It 
seems on the surface to be very similar to Tanh, as you correctly point 
out. But for some reason it seems to be more conservative than Tanh. And
 sometimes that means it’s too conservative so when it arrives at an 
approximate solution it stays there.</p>
<p>That’s the best reason I can give you for why Tanh is better: It 
seems to be less conservative than Sigmoid. I could probably give you a 
better reason if I spend a bit of time debugging this and watching it in
 more detail, but I don’t think that’s worth doing for me since I’m 
still new to the field. I’ll just use the things that have proven good 
experimentally.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2704#respond" onclick='return addComment.moveForm( "div-comment-2704", "2704", "respond", "2435" )' aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment even depth-3 highlander-comment" id="comment-2716">
				<div id="div-comment-2716" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/e31d7c3f1f052f5694a083055887156b.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-e31d7c3f1f052f5694a083055887156b-0" width="48" height="48">			<cite class="fn"><a href="http://gravatar.com/pse1202" rel="external nofollow" class="url">Sam Park</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2716">
			May 9, 2016 at 00:10</a>		</div>

		<p>In many cases, ReLU and its modifications are used instead of 
sigmoid or tanh. The main reason is that it is much more faster. 
Exponential functions are very expensive when calculating sigmoid 
functions compared to the simplicity of ReLU.</p>

		
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2697">
				<div id="div-comment-2697" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/6568504bfd4f071c1847be37aaf20ec3.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-6568504bfd4f071c1847be37aaf20ec3-0" width="48" height="48">			<cite class="fn">Al Rahat</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2697">
			April 30, 2016 at 19:52</a>		</div>

		<p>Not sure if you’ve seen this paper: <a href="http://arxiv.org/pdf/1511.06085v5.pdf" rel="nofollow">http://arxiv.org/pdf/1511.06085v5.pdf</a> but it seems that they take what you wrote about to the next level.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2697#respond" onclick='return addComment.moveForm( "div-comment-2697", "2697", "respond", "2435" )' aria-label="Reply to Al Rahat">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor even depth-2 highlander-comment" id="comment-2708">
				<div id="div-comment-2708" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-32d3ef171bc897317c4a77a83f44fbcb-2" width="48" height="48">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2708">
			May 1, 2016 at 15:33</a>		</div>

		<p>Love it, thanks for the link!</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2708#respond" onclick='return addComment.moveForm( "div-comment-2708", "2708", "respond", "2435" )' aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2698">
				<div id="div-comment-2698" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/c2a2c0b6dd4808989adcd863123fa585.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-c2a2c0b6dd4808989adcd863123fa585-0" width="48" height="48">			<cite class="fn">leo</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2698">
			April 30, 2016 at 20:09</a>		</div>

		<p>Have you thought of entering a compression algorithm for the Hutter prize?</p>
<p><a href="https://en.wikipedia.org/wiki/Hutter_Prize" rel="nofollow">https://en.wikipedia.org/wiki/Hutter_Prize</a></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2698#respond" onclick='return addComment.moveForm( "div-comment-2698", "2698", "respond", "2435" )' aria-label="Reply to leo">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor even depth-2 highlander-comment" id="comment-2707">
				<div id="div-comment-2707" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-32d3ef171bc897317c4a77a83f44fbcb-3" width="48" height="48">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2707">
			May 1, 2016 at 15:23</a>		</div>

		<p>I’m not sure if this would work for text compression. It works as 
long as you have nice clean patterns like I have, but the problem is 
that you get fuzzy results for more complex cases. Like let’s say your 
network is trying to learn the word “HELLO”; you have four input nodes: 
E, H, L, and O; and five output nodes: E, H, L, O and ‘end of text’. 
That setup will learn the word, but it has to learn that for the letter L
 it has to either output a second L or an O.</p>
<p>So now your network will either output “HELLO” or “HELO” or “HELLLO” 
or any other multiple of Ls. (though they get less likely the further 
you are from the truth) There are ways to solve this and that is the 
next thing I want to learn in neural networks, but I think once you 
leave simple examples you always have that fuzziness in there. And 
fuzziness is not something you want in text compression <img draggable="false" class="emoji" alt="😉" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/1f609.svg"></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2707#respond" onclick='return addComment.moveForm( "div-comment-2707", "2707", "respond", "2435" )' aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2699">
				<div id="div-comment-2699" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/bf239d8fd2063bb9776944028e649c62.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-bf239d8fd2063bb9776944028e649c62-0" width="48" height="48">			<cite class="fn">Pablo Arias</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2699">
			April 30, 2016 at 21:17</a>		</div>

		<p>Why tanh? Because it has a couple convenient properties, and it 
happens to work better than other functions that have the same 
properties. But mostly it’s “beause it works like this and it doesn’t 
work when we change it.”</p>
<p>Not completly true. tanh() cane to replace a very popular function in
 NN, sinh(). It works better because 1) it looks more like the way real 
neurons trigger, and 2) it has a stepper transition, it dwells less in 
the meta stable region</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2699#respond" onclick='return addComment.moveForm( "div-comment-2699", "2699", "respond", "2435" )' aria-label="Reply to Pablo Arias">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment even depth-2 highlander-comment" id="comment-2700">
				<div id="div-comment-2700" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/e214f5c143b40458c473bef6ee05823e.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-e214f5c143b40458c473bef6ee05823e-1" width="48" height="48">			<cite class="fn">Martin Cohen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2700">
			April 30, 2016 at 22:07</a>		</div>

		<p>Are you sure you mean “sinh”? That get very large very fast. Maybe inverse tan?</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2700#respond" onclick='return addComment.moveForm( "div-comment-2700", "2700", "respond", "2435" )' aria-label="Reply to Martin Cohen">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-tgsmith61591 odd alt thread-odd thread-alt depth-1 parent highlander-comment" id="comment-2701">
				<div id="div-comment-2701" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/31ccee0370328a7c894902c0a70373f7.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-31ccee0370328a7c894902c0a70373f7-0" width="48" height="48">			<cite class="fn">tgsmith61591</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2701">
			May 1, 2016 at 07:33</a>		</div>

		<p>Actually worth noting that contemporary research suggests the 
rectifier (max(x,0)) to be the most biologically plausible activation 
function, as it tends to create a more sparse network. But, there is no 
silver bullet. In that sense, I have to disagree with your “it works 
this way just because, and if we change it, it won’t” assertion. </p>
<p>Source: <a href="http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf" rel="nofollow">http://jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf</a></p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2701#respond" onclick='return addComment.moveForm( "div-comment-2701", "2701", "respond", "2435" )' aria-label="Reply to tgsmith61591">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment byuser comment-author-sagan1338 bypostauthor even depth-2 highlander-comment" id="comment-2706">
				<div id="div-comment-2706" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/32d3ef171bc897317c4a77a83f44fbcb.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-32d3ef171bc897317c4a77a83f44fbcb-4" width="48" height="48">			<cite class="fn"><a href="https://probablydance.wordpress.com/" rel="external nofollow" class="url">Malte Skarupke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2706">
			May 1, 2016 at 15:12</a>		</div>

		<p>Yeah I like ReLU much more than tanh because it’s something that 
was at least arrived at by design. I can understand the motivation 
behind it and I can build a better mental model for it than for Tanh.</p>
<p>That being said if I use ReLU for the middle layer here, I need four 
nodes in the middle instead of two. If this was a real compression 
algorithm and if my compressed data suddenly became twice as large, that
 would be a very bad change. So ReLU is not that great a choice at least
 for this specific problem. But then maybe ReLU does better once I have 
more connections because then Tanh will start to trample over its own 
constructions all the time while ReLU nodes tend to get out of each 
others way. But see, that’s where it gets too handwavy for me again…</p>
<p>And that paper is a typical paper from neural networks including the 
language that I don’t like. For example they have a part about softplus 
where they essentially say “you’d think that softplus has the same 
benefits as ReLU without the downsides, but our experiments show that 
that’s not the case. Here’s an idea for why that might be.” And then 
they just leave it at that. There’s some rigor missing here. If you put 
out an idea like that you should at least come up with some test for 
that idea and show that your idea passes that test. Any test would have 
been better than just leaving it like this. Here’s the sentence in 
question: “We hypothesize that the hard non-linearities do not hurt so 
long as the gradient can propagate along some paths, i.e., that some of 
the hidden units in each layer are non-zero. With the credit and blame 
assigned to these ON units rather than distributed more evenly, we 
hypothesize that optimization is easier.”</p>
<p>It’s a nice story and it’s plausible, but I can come up with lots of 
plausible stories. Like my explanation above where I say that the hard 
zeros help because without it nodes tend to step on each others toes 
more often when they optimize. That is something that I have observed, 
especially if certain outputs are more common in the data. Things that 
are more common tend to trample all over your less common cases. Batch 
updating seems to help with that, and the hard zeros of ReLU nodes 
should also help with that. Is my explanation plausible? Yes. Would I 
write this theory in a paper without at least some test to falsify it? 
No. (oh and the way you’d falsify this idea is that you’d set up a test 
where some outputs are far more common than others and you show that 
other methods trample all over the weights of less common cases, but 
ReLU doesn’t. You’d have to watch individual weights in your network to 
confirm or deny this. If you see that ReLU is trampling over rare cases 
just as much as other methods are, then the story is not true no matter 
how plausible it sounded)</p>
<p>Since their paper is so much about sparsity, I would have wanted them
 to test that theory specifically. Like if sparsity helps, couldn’t you 
use that knowledge to improve tanh()? Just force some values to zero and
 keep them there forever. If sparsity really helps, you would expect the
 performance of tanh to also increase. They didn’t do a test like this. 
Instead all of their theories are supported by the fact that “it works 
like this.”</p>
<p>All that being said I think they arrived at a good model with ReLU. 
And obviously you can get to really good results by constantly coming up
 with new things that work. But my experience has shown that you can get
 better results if you know why they work. (and not just if you think 
you know why they work)</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2706#respond" onclick='return addComment.moveForm( "div-comment-2706", "2706", "respond", "2435" )' aria-label="Reply to Malte Skarupke">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent highlander-comment" id="comment-2705">
				<div id="div-comment-2705" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/522e14016606fa348941f854ddd5fb8c.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-522e14016606fa348941f854ddd5fb8c-0" width="48" height="48">			<cite class="fn">Binesh</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2705">
			May 1, 2016 at 14:41</a>		</div>

		<p>I think the reason tanh works better is because it’s centered at 
zero.. Or tanh(0) = 0 whereas sigmoid(0) = .5… If you work it through, 
you’ll see that as you add layers this starts pushing all the nodes 
towards higher and higher values…</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2705#respond" onclick='return addComment.moveForm( "div-comment-2705", "2705", "respond", "2435" )' aria-label="Reply to Binesh">Reply</a></div>
				</div>
		<ul class="children">
		<li class="comment even depth-2 highlander-comment" id="comment-2709">
				<div id="div-comment-2709" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/e214f5c143b40458c473bef6ee05823e.png" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-e214f5c143b40458c473bef6ee05823e-2" width="48" height="48">			<cite class="fn">Martin Cohen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-2709">
			May 1, 2016 at 15:49</a>		</div>

		<p>I think I said a shifted sigmoid, which is, after scaling, identical to tanh.</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=2709#respond" onclick='return addComment.moveForm( "div-comment-2709", "2709", "respond", "2435" )' aria-label="Reply to Martin Cohen">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
</ul><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-pirateyoshi odd alt thread-odd thread-alt depth-1 highlander-comment" id="comment-3084">
				<div id="div-comment-3084" class="comment-body">
				<div class="comment-author vcard">
			<img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/3c83b477629072469dc3898e1629024f.jpeg" class="avatar avatar-48 grav-hashed grav-hijack" id="grav-3c83b477629072469dc3898e1629024f-0" width="48" height="48">			<cite class="fn">Ziru</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#comment-3084">
			April 22, 2017 at 00:54</a>		</div>

		<p>Great read. Thanks for taking the time to write it ^^</p>

		<div class="reply"><a rel="nofollow" class="comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/?replytocom=3084#respond" onclick='return addComment.moveForm( "div-comment-3084", "3084", "respond", "2435" )' aria-label="Reply to Ziru">Reply</a></div>
				</div>
		</li><!-- #comment-## -->
		</ol>

		<div class="navigation">
			<div class="alignleft"></div>
			<div class="alignright"></div>
		</div>
 	
		<div id="respond" class="comment-respond js">
		<h3 id="reply-title" class="comment-reply-title">Leave a Reply <small><a rel="nofollow" id="cancel-comment-reply-link" href="https://probablydance.com/2016/04/30/neural-networks-are-impressively-good-at-compression/#respond" style="display:none;">Cancel reply</a></small></h3>			<form action="https://probablydance.com/wp-comments-post.php" method="post" id="commentform" class="comment-form">
				<input id="highlander_comment_nonce" name="highlander_comment_nonce" value="b1149bdf95" type="hidden"><input name="_wp_http_referer" value="/2016/04/30/neural-networks-are-impressively-good-at-compression/" type="hidden">
<input name="hc_post_as" id="hc_post_as" value="guest" type="hidden">

<div class="comment-form-field comment-textarea">
	
	<div id="comment-form-comment"><textarea tabindex="-1" style="position: absolute; top: -999px; left: 0px; right: auto; bottom: auto; border: 0px none; padding: 0px; box-sizing: content-box; overflow-wrap: break-word; height: 0px !important; min-height: 0px !important; overflow: hidden; transition: none 0s ease 0s; font-family: Arial, Helvetica, Tahoma, Verdana, sans-serif; font-size: 14px; font-weight: 400; font-style: normal; letter-spacing: 0px; text-transform: none; text-decoration: none; word-spacing: 0px; text-indent: 0px; line-height: 16px; width: 628px;" class="autosizejs ">Enter your comment here...</textarea><textarea id="comment" name="comment" title="Enter your comment here..." placeholder="Enter your comment here..." style="height: 36px; overflow: hidden; overflow-wrap: break-word; resize: none;"></textarea></div>
</div>

<div id="comment-form-identity" style="display: none;">

	<div id="comment-form-nascar">
		<p>Fill in your details below or click an icon to log in:</p>
		<ul>
			<li class="selected" style="display:none;">
				<a href="#comment-form-guest" id="postas-guest" title="Guest">
					<span></span>
				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:WordPress.com" id="postas-wordpress" title="WordPress.com">
					<span></span>
				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Twitter" id="postas-twitter" title="Twitter">
					<span></span>
				</a>
			</li>
			<li>
				<a href="#comment-form-load-service:Facebook" id="postas-facebook" title="Facebook">
					<span></span>
				</a>
			</li>
			<li>
		</li></ul>
	</div>

	<div id="comment-form-guest" class="comment-form-service selected">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
<a href="https://gravatar.com/site/signup/" target="_blank">				<img src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/ad516503a11cd5ca435acc9bb6523536.png" alt="Gravatar" class="no-grav" width="25">
</a>			</div>

				<div class="comment-form-fields">
				<div class="comment-form-field comment-form-email">
					<label for="email">Email <span class="required">(required)</span> <span class="nopublish">(Address never made public)</span></label>
					<div class="comment-form-input"><input id="email" name="email" type="email"></div>
				</div>
				<div class="comment-form-field comment-form-author">
					<label for="author">Name <span class="required">(required)</span></label>
					<div class="comment-form-input"><input id="author" name="author" type="text"></div>
				</div>
				<div class="comment-form-field comment-form-url">
					<label for="url">Website</label>
					<div class="comment-form-input"><input id="url" name="url" type="url"></div>
				</div>
			</div>
	
		</div>
	</div>

	<div id="comment-form-wordpress" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/ad516503a11cd5ca435acc9bb6523536.png" alt="WordPress.com Logo" class="no-grav" width="25">
			</div>

				<div class="comment-form-fields">
				<input name="wp_avatar" id="wordpress-avatar" class="comment-meta-wordpress" value="" type="hidden">
				<input name="wp_user_id" id="wordpress-user_id" class="comment-meta-wordpress" value="" type="hidden">
				<input name="wp_access_token" id="wordpress-access_token" class="comment-meta-wordpress" value="" type="hidden">
				<p class="comment-form-posting-as pa-wordpress"><strong></strong> You are commenting using your WordPress.com account. <span class="comment-form-log-out">(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout(%20'wordpress'%20);">Log&nbsp;Out</a>&nbsp;/&nbsp;<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)</span></p>
			</div>
	
		</div>
	</div>

	<div id="comment-form-twitter" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/ad516503a11cd5ca435acc9bb6523536.png" alt="Twitter picture" class="no-grav" width="25">
			</div>

				<div class="comment-form-fields">
				<input name="twitter_avatar" id="twitter-avatar" class="comment-meta-twitter" value="" type="hidden">
				<input name="twitter_user_id" id="twitter-user_id" class="comment-meta-twitter" value="" type="hidden">
				<input name="twitter_access_token" id="twitter-access_token" class="comment-meta-twitter" value="" type="hidden">
				<p class="comment-form-posting-as pa-twitter"><strong></strong> You are commenting using your Twitter account. <span class="comment-form-log-out">(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout(%20'twitter'%20);">Log&nbsp;Out</a>&nbsp;/&nbsp;<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)</span></p>
			</div>
	
		</div>
	</div>

	<div id="comment-form-facebook" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/ad516503a11cd5ca435acc9bb6523536.png" alt="Facebook photo" class="no-grav" width="25">
			</div>

				<div class="comment-form-fields">
				<input name="fb_avatar" id="facebook-avatar" class="comment-meta-facebook" value="" type="hidden">
				<input name="fb_user_id" id="facebook-user_id" class="comment-meta-facebook" value="" type="hidden">
				<input name="fb_access_token" id="facebook-access_token" class="comment-meta-facebook" value="" type="hidden">
				<p class="comment-form-posting-as pa-facebook"><strong></strong> You are commenting using your Facebook account. <span class="comment-form-log-out">(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout(%20'facebook'%20);">Log&nbsp;Out</a>&nbsp;/&nbsp;<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)</span></p>
			</div>
	
		</div>
	</div>

	<div id="comment-form-googleplus" class="comment-form-service">
		<div class="comment-form-padder">
			<div class="comment-form-avatar">
				<img src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/ad516503a11cd5ca435acc9bb6523536.png" alt="Google+ photo" class="no-grav" width="25">
			</div>

				<div class="comment-form-fields">
				<input name="googleplus_avatar" id="googleplus-avatar" class="comment-meta-googleplus" value="" type="hidden">
				<input name="googleplus_user_id" id="googleplus-user_id" class="comment-meta-googleplus" value="" type="hidden">
				<input name="googleplus_access_token" id="googleplus-access_token" class="comment-meta-googleplus" value="" type="hidden">
				<p class="comment-form-posting-as pa-googleplus"><strong></strong> You are commenting using your Google+ account. <span class="comment-form-log-out">(&nbsp;<a href="javascript:HighlanderComments.doExternalLogout(%20'googleplus'%20);">Log&nbsp;Out</a>&nbsp;/&nbsp;<a href="#" onclick="javascript:HighlanderComments.switchAccount();return false;">Change</a>&nbsp;)</span></p>
			</div>
	
		</div>
	</div>


	<div id="comment-form-load-service" class="comment-form-service">
		<div class="comment-form-posting-as-cancel"><a href="javascript:HighlanderComments.cancelExternalWindow();">Cancel</a></div>
		<p>Connecting to %s</p>
	</div>

</div>

<script type="text/javascript">
var highlander_expando_javascript = function(){
	var input = document.createElement( 'input' ),
	    comment = jQuery( '#comment' );

	if ( 'placeholder' in input ) {
		comment.attr( 'placeholder', jQuery( '.comment-textarea label' ).remove().text() );
	}

	// Expando Mode: start small, then auto-resize on first click + text length
	jQuery( '#comment-form-identity' ).hide();
	jQuery( '#comment-form-subscribe' ).hide();
	jQuery( '#commentform .form-submit' ).hide();

	comment.css( { 'height':'10px' } ).one( 'focus', function() {
		var timer = setInterval( HighlanderComments.resizeCallback, 10 )
		jQuery( this ).animate( { 'height': HighlanderComments.initialHeight } ).delay( 100 ).queue( function(n) { clearInterval( timer ); HighlanderComments.resizeCallback(); n(); } );
		jQuery( '#comment-form-identity' ).slideDown();
		jQuery( '#comment-form-subscribe' ).slideDown();
		jQuery( '#commentform .form-submit' ).slideDown();
	});
}
jQuery(document).ready( highlander_expando_javascript );
</script>

<div id="comment-form-subscribe" style="display: none;">
	<p class="comment-subscription-form"><input name="subscribe" id="subscribe" value="subscribe" style="width: auto;" type="checkbox"> <label class="subscribe-label" id="subscribe-label" for="subscribe" style="display: inline;">Notify me of new comments via email.</label></p></div>




<p class="form-submit" style="display: none;"><input name="submit" id="comment-submit" class="submit" value="Post Comment" type="submit"> <input name="comment_post_ID" value="2435" id="comment_post_ID" type="hidden">
<input name="comment_parent" id="comment_parent" value="0" type="hidden">
</p><p style="display: none;"><input id="akismet_comment_nonce" name="akismet_comment_nonce" value="03716bc578" type="hidden"></p>
<input name="genseq" value="1520070916" type="hidden">
<p style="display: none;"></p>			<input id="ak_js" name="ak_js" value="1520070916640" type="hidden"></form>
			</div><!-- #respond -->
	<div style="clear: both"></div></div>
	<div class="navigation">
		<div class="prev"><a href="https://probablydance.com/2016/03/25/vr-will-be-about-using-your-hands/" rel="prev">« Previous Post</a></div>
		<div class="next"><a href="https://probablydance.com/2016/06/03/c11-completed-raii-making-composition-easier/" rel="next">Next Post »</a></div>
	</div>


</div><!-- #core-content -->


</div><!-- #site-wrapper -->

<div id="footer">

	
<div id="supplementary" class="one">

		<div id="first" class="widget-area" role="complementary">
		<aside id="search-2" class="widget widget_search"><form role="search" method="get" id="searchform" class="searchform" action="https://probablydance.com/">
				<div>
					<label class="screen-reader-text" for="s">Search for:</label>
					<input name="s" id="s" type="text">
					<input id="searchsubmit" value="Search" type="submit">
				</div>
			</form></aside>		<aside id="recent-posts-2" class="widget widget_recent_entries">		<h4 class="widget-title">Recent Posts</h4>		<ul>
											<li>
					<a href="https://probablydance.com/2018/01/25/finding-floating-point-numbers-for-exact-math/">Finding Floating Point Numbers for Exact&nbsp;Math</a>
									</li>
											<li>
					<a href="https://probablydance.com/2017/12/18/where-do-top-scientists-come-from-and-what-do-taxes-have-to-do-with-it/">Where do top scientists come from? And what do taxes have to do with&nbsp;it?</a>
									</li>
											<li>
					<a href="https://probablydance.com/2017/11/24/games-are-about-personal-development/">Games Are About Personal&nbsp;Development</a>
									</li>
											<li>
					<a href="https://probablydance.com/2017/10/09/evidence-for-how-to-make-great-games/">Evidence For How To Make Great&nbsp;Games</a>
									</li>
											<li>
					<a href="https://probablydance.com/2017/09/02/collected-advice-for-doing-scientific-research/">Collected Advice for Doing Scientific&nbsp;Research</a>
									</li>
					</ul>
		</aside><aside id="archives-2" class="widget widget_archive"><h4 class="widget-title">Archives</h4>		<ul>
			<li><a href="https://probablydance.com/2018/01/">January 2018</a></li>
	<li><a href="https://probablydance.com/2017/12/">December 2017</a></li>
	<li><a href="https://probablydance.com/2017/11/">November 2017</a></li>
	<li><a href="https://probablydance.com/2017/10/">October 2017</a></li>
	<li><a href="https://probablydance.com/2017/09/">September 2017</a></li>
	<li><a href="https://probablydance.com/2017/08/">August 2017</a></li>
	<li><a href="https://probablydance.com/2017/02/">February 2017</a></li>
	<li><a href="https://probablydance.com/2017/01/">January 2017</a></li>
	<li><a href="https://probablydance.com/2016/12/">December 2016</a></li>
	<li><a href="https://probablydance.com/2016/11/">November 2016</a></li>
	<li><a href="https://probablydance.com/2016/06/">June 2016</a></li>
	<li><a href="https://probablydance.com/2016/04/">April 2016</a></li>
	<li><a href="https://probablydance.com/2016/03/">March 2016</a></li>
	<li><a href="https://probablydance.com/2016/02/">February 2016</a></li>
	<li><a href="https://probablydance.com/2015/12/">December 2015</a></li>
	<li><a href="https://probablydance.com/2015/09/">September 2015</a></li>
	<li><a href="https://probablydance.com/2015/07/">July 2015</a></li>
	<li><a href="https://probablydance.com/2015/06/">June 2015</a></li>
	<li><a href="https://probablydance.com/2015/05/">May 2015</a></li>
	<li><a href="https://probablydance.com/2015/02/">February 2015</a></li>
	<li><a href="https://probablydance.com/2015/01/">January 2015</a></li>
	<li><a href="https://probablydance.com/2014/12/">December 2014</a></li>
	<li><a href="https://probablydance.com/2014/11/">November 2014</a></li>
	<li><a href="https://probablydance.com/2014/10/">October 2014</a></li>
	<li><a href="https://probablydance.com/2014/09/">September 2014</a></li>
	<li><a href="https://probablydance.com/2014/08/">August 2014</a></li>
	<li><a href="https://probablydance.com/2014/06/">June 2014</a></li>
	<li><a href="https://probablydance.com/2014/05/">May 2014</a></li>
	<li><a href="https://probablydance.com/2014/04/">April 2014</a></li>
	<li><a href="https://probablydance.com/2014/03/">March 2014</a></li>
	<li><a href="https://probablydance.com/2014/02/">February 2014</a></li>
	<li><a href="https://probablydance.com/2014/01/">January 2014</a></li>
	<li><a href="https://probablydance.com/2013/10/">October 2013</a></li>
	<li><a href="https://probablydance.com/2013/09/">September 2013</a></li>
	<li><a href="https://probablydance.com/2013/08/">August 2013</a></li>
	<li><a href="https://probablydance.com/2013/05/">May 2013</a></li>
	<li><a href="https://probablydance.com/2013/02/">February 2013</a></li>
	<li><a href="https://probablydance.com/2013/01/">January 2013</a></li>
	<li><a href="https://probablydance.com/2012/12/">December 2012</a></li>
	<li><a href="https://probablydance.com/2012/11/">November 2012</a></li>
	<li><a href="https://probablydance.com/2012/10/">October 2012</a></li>
	<li><a href="https://probablydance.com/2012/08/">August 2012</a></li>
	<li><a href="https://probablydance.com/2012/07/">July 2012</a></li>
	<li><a href="https://probablydance.com/2012/04/">April 2012</a></li>
	<li><a href="https://probablydance.com/2012/03/">March 2012</a></li>
	<li><a href="https://probablydance.com/2012/02/">February 2012</a></li>
	<li><a href="https://probablydance.com/2012/01/">January 2012</a></li>
	<li><a href="https://probablydance.com/2011/10/">October 2011</a></li>
	<li><a href="https://probablydance.com/2011/09/">September 2011</a></li>
	<li><a href="https://probablydance.com/2011/08/">August 2011</a></li>
	<li><a href="https://probablydance.com/2011/07/">July 2011</a></li>
	<li><a href="https://probablydance.com/2011/06/">June 2011</a></li>
	<li><a href="https://probablydance.com/2011/05/">May 2011</a></li>
		</ul>
		</aside><aside id="categories-2" class="widget widget_categories"><h4 class="widget-title">Categories</h4>		<ul>
	<li class="cat-item cat-item-21"><a href="https://probablydance.com/category/games/">Games</a>
</li>
	<li class="cat-item cat-item-2200"><a href="https://probablydance.com/category/programming/links/">Links</a>
</li>
	<li class="cat-item cat-item-13677"><a href="https://probablydance.com/category/politics-and-economics/">Politics and Economics</a>
</li>
	<li class="cat-item cat-item-196"><a href="https://probablydance.com/category/programming/">Programming</a>
</li>
	<li class="cat-item cat-item-1"><a href="https://probablydance.com/category/uncategorized/">Uncategorized</a>
</li>
		</ul>
</aside><aside id="meta-2" class="widget widget_meta"><h4 class="widget-title">Meta</h4>			<ul>
			<li><a href="https://wordpress.com/start?ref=wplogin">Register</a></li>			<li><a href="https://probablydance.wordpress.com/wp-login.php">Log in</a></li>
			<li><a href="https://probablydance.com/feed/">Entries <abbr title="Really Simple Syndication">RSS</abbr></a></li>
			<li><a href="https://probablydance.com/comments/feed/">Comments <abbr title="Really Simple Syndication">RSS</abbr></a></li>
			<li><a href="https://wordpress.com/" title="Powered by WordPress, state-of-the-art semantic personal publishing platform.">WordPress.com</a></li>			</ul>
			</aside>	</div>
	
	
</div>
	<!-- Search Field -->
	<div class="footer-content">
		<form method="get" id="searchform" action="https://probablydance.com/">
			<div id="search">
				<input name="s" id="s" type="text">
				<input id="searchsubmit" value="Search" type="submit">
			</div>
		</form>
		<p>
			<a href="https://wordpress.com/?ref=footer_blog">Blog at WordPress.com.</a>
					</p>
	</div>
</div><!-- #footer -->

<!--  -->
<script type="text/javascript" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/gprofiles.js"></script>
<script type="text/javascript">
/* <![CDATA[ */
var WPGroHo = {"my_hash":""};
/* ]]> */
</script>
<script type="text/javascript" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/wpgroho.js"></script>

	<script>
		//initialize and attach hovercards to all gravatars
		jQuery( document ).ready( function( $ ) {

			if (typeof Gravatar === "undefined"){
				return;
			}

			if ( typeof Gravatar.init !== "function" ) {
				return;
			}			

			Gravatar.profile_cb = function( hash, id ) {
				WPGroHo.syncProfileData( hash, id );
			};
			Gravatar.my_hash = WPGroHo.my_hash;
			Gravatar.init( 'body', '#wp-admin-bar-my-account' );
		});
	</script>

		<div style="display:none">
	<div class="grofile-hash-map-866ac17d713ed49c713e14e9b4ba34ab">
	</div>
	<div class="grofile-hash-map-32d3ef171bc897317c4a77a83f44fbcb">
	</div>
	<div class="grofile-hash-map-e214f5c143b40458c473bef6ee05823e">
	</div>
	<div class="grofile-hash-map-e31d7c3f1f052f5694a083055887156b">
	</div>
	<div class="grofile-hash-map-6568504bfd4f071c1847be37aaf20ec3">
	</div>
	<div class="grofile-hash-map-c2a2c0b6dd4808989adcd863123fa585">
	</div>
	<div class="grofile-hash-map-bf239d8fd2063bb9776944028e649c62">
	</div>
	<div class="grofile-hash-map-31ccee0370328a7c894902c0a70373f7">
	</div>
	<div class="grofile-hash-map-522e14016606fa348941f854ddd5fb8c">
	</div>
	<div class="grofile-hash-map-3c83b477629072469dc3898e1629024f">
	</div>
	</div>
<script type="text/javascript">
/* <![CDATA[ */
var HighlanderComments = {"loggingInText":"Logging 
In\u2026","submittingText":"Posting 
Comment\u2026","postCommentText":"Post 
Comment","connectingToText":"Connecting to %s","commentingAsText":"%1$s:
 You are commenting using your %2$s account.","logoutText":"Log 
Out","loginText":"Log 
In","connectURL":"https:\/\/probablydance.wordpress.com\/public.api\/connect\/?action=request","logoutURL":"https:\/\/probablydance.wordpress.com\/wp-login.php?action=logout&_wpnonce=68546244c0","homeURL":"https:\/\/probablydance.com\/","postID":"2435","gravDefault":"identicon","enterACommentError":"Please
 enter a comment","enterEmailError":"Please enter your email address 
here","invalidEmailError":"Invalid email 
address","enterAuthorError":"Please enter your name 
here","gravatarFromEmail":"This picture will show whenever you leave a 
comment. Click to customize it.","logInToExternalAccount":"Log in to use
 details from one of these 
accounts.","change":"Change","changeAccount":"Change 
Account","comment_registration":"0","userIsLoggedIn":"","isJetpack":"","text_direction":"ltr"};
/*
 ]]> */
</script>
<script type="text/javascript" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a_003"></script>

	<div id="carousel-reblog-box">
		<form action="#" name="carousel-reblog">
			<textarea id="carousel-reblog-content" name="carousel-reblog-content" placeholder="Add your thoughts here... (optional)"></textarea>
			<label for="carousel-reblog-to-blog-id" id="carousel-reblog-lblogid">Post to</label>
			<select name="carousel-reblog-to-blog-id" id="carousel-reblog-to-blog-id">
						</select>

			<div class="submit">
				<span class="canceltext"><a href="#" class="cancel">Cancel</a></span>
				<input name="carousel-reblog-submit" class="button" id="carousel-reblog-submit" value="Reblog Post" type="submit">
				<input id="carousel-reblog-blog-id" value="22872755" type="hidden">
				<input id="carousel-reblog-blog-url" value="https://probablydance.com" type="hidden">
				<input id="carousel-reblog-blog-title" value="Probably Dance" type="hidden">
				<input id="carousel-reblog-post-url" value="" type="hidden">
				<input id="carousel-reblog-post-title" value="" type="hidden">
			</div>

			<input id="_wpnonce" name="_wpnonce" value="ecc561b64b" type="hidden"><input name="_wp_http_referer" value="/2016/04/30/neural-networks-are-impressively-good-at-compression/" type="hidden">		</form>

		<div class="arrow"></div>
	</div>

	<script type="text/javascript">
		window.WPCOM_sharing_counts = 
{"https:\/\/probablydance.com\/2016\/04\/30\/neural-networks-are-impressively-good-at-compression\/":2435};

	</script>
		<script type="text/javascript">
			var windowOpen;
		jQuery(document).on( 'ready post-load', function(){
			jQuery( 'a.share-twitter' ).on( 'click', function() {
				if ( 'undefined' !== typeof windowOpen ){ // If there's another sharing window open, close it.
					windowOpen.close();
				}
				windowOpen = window.open( jQuery(this).attr( 'href' ), 'wpcomtwitter', 'menubar=1,resizable=1,width=600,height=350' );
				return false;
			});
		});
		</script>
				<script type="text/javascript">
			var windowOpen;
		jQuery(document).on( 'ready post-load', function(){
			jQuery( 'a.share-facebook' ).on( 'click', function() {
				if ( 'undefined' !== typeof windowOpen ){ // If there's another sharing window open, close it.
					windowOpen.close();
				}
				windowOpen = window.open( jQuery(this).attr( 'href' ), 'wpcomfacebook', 'menubar=1,resizable=1,width=600,height=400' );
				return false;
			});
		});
		</script>
		<link rel="stylesheet" id="all-css-0-3" href="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/jetpack-carousel.css" type="text/css" media="all">
<!--[if lte IE 8]>
<link rel='stylesheet' id='jetpack-carousel-ie8fix-css'  href='https://s1.wp.com/wp-content/mu-plugins/carousel/jetpack-carousel-ie8fix.css?m=1412618825h&#038;ver=20121024' type='text/css' media='all' />
<![endif]-->
<script type="text/javascript">
/* <![CDATA[ */
var actionbardata = {"siteID":"22872755","siteName":"Probably 
Dance","siteURL":"https:\/\/probablydance.com","icon":"<img alt='' 
src='https:\/\/s1.wp.com\/i\/logo\/wpcom-gray-white.png' class='avatar 
avatar-50' height='50' width='50' 
\/>","canManageOptions":"","canCustomizeSite":"","isFollowing":"","themeSlug":"pub\/manifest","signupURL":"https:\/\/wordpress.com\/start\/","loginURL":"https:\/\/probablydance.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F","themeURL":"","xhrURL":"https:\/\/probablydance.com\/wp-admin\/admin-ajax.php","nonce":"2bc9ed17f6","isSingular":"1","isFolded":"","isLoggedIn":"","isMobile":"","subscribeNonce":"<input
 type=\"hidden\" id=\"_wpnonce\" name=\"_wpnonce\" value=\"12d57154cd\" 
\/>","referer":"https:\/\/probablydance.com\/2016\/04\/30\/neural-networks-are-impressively-good-at-compression\/","canFollow":"1","feedID":"1759169","statusMessage":"","customizeLink":"https:\/\/probablydance.wordpress.com\/wp-admin\/customize.php?url=https%3A%2F%2Fprobablydance.wordpress.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F","postID":"2435","shortlink":"https:\/\/wp.me\/p1xYfp-Dh","canEditPost":"","editLink":"https:\/\/wordpress.com\/post\/probablydance.com\/2435","statsLink":"https:\/\/wordpress.com\/stats\/post\/2435\/probablydance.com","i18n":{"view":"View
 
site","follow":"Follow","following":"Following","edit":"Edit","login":"Log
 in","signup":"Sign up","customize":"Customize","report":"Report this 
content","themeInfo":"Get theme: Manifest","shortlink":"Copy 
shortlink","copied":"Copied","followedText":"New posts from this site 
will now appear in your <a 
href=\"https:\/\/wordpress.com\/\">Reader<\/a>","foldBar":"Collapse this
 bar","unfoldBar":"Expand this bar","editSubs":"Manage 
subscriptions","viewReader":"View site in Reader","viewReadPost":"View 
post in Reader","subscribe":"Sign me up","enterEmail":"Enter your email 
address","followers":"Join 73 other followers","alreadyUser":"Already 
have a WordPress.com account? <a 
href=\"https:\/\/probablydance.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F\">Log
 in now.<\/a>","stats":"Stats"}};
/* ]]> */
</script>
<script type="text/javascript">
/* <![CDATA[ */
var jetpackCarouselStrings = 
{"widths":[370,700,1000,1200,1400,2000],"is_logged_in":"","lang":"en","ajaxurl":"https:\/\/probablydance.com\/wp-admin\/admin-ajax.php","nonce":"966fef4f2f","display_exif":"1","display_geo":"1","single_image_gallery":"1","single_image_gallery_media_file":"","background_color":"black","comment":"Comment","post_comment":"Post
 Comment","write_comment":"Write a 
Comment...","loading_comments":"Loading 
Comments...","download_original":"View full size <span 
class=\"photo-size\">{0}<span 
class=\"photo-size-times\">\u00d7<\/span>{1}<\/span>","no_comment_text":"Please
 be sure to submit some text with your 
comment.","no_comment_email":"Please provide an email address to 
comment.","no_comment_author":"Please provide your name to 
comment.","comment_post_error":"Sorry, but there was an error posting 
your comment. Please try again later.","comment_approved":"Your comment 
was approved.","comment_unapproved":"Your comment is in 
moderation.","camera":"Camera","aperture":"Aperture","shutter_speed":"Shutter
 Speed","focal_length":"Focal 
Length","comment_registration":"0","require_name_email":"1","login_url":"https:\/\/probablydance.wordpress.com\/wp-login.php?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F","blog_id":"22872755","local_comments_commenting_as":"<fieldset><label
 for=\"email\">Email (Required)<\/label> <input type=\"text\" 
name=\"email\" class=\"jp-carousel-comment-form-field 
jp-carousel-comment-form-text-field\" 
id=\"jp-carousel-comment-form-email-field\" 
\/><\/fieldset><fieldset><label for=\"author\">Name (Required)<\/label> 
<input type=\"text\" name=\"author\" 
class=\"jp-carousel-comment-form-field 
jp-carousel-comment-form-text-field\" 
id=\"jp-carousel-comment-form-author-field\" 
\/><\/fieldset><fieldset><label for=\"url\">Website<\/label> <input 
type=\"text\" name=\"url\" class=\"jp-carousel-comment-form-field 
jp-carousel-comment-form-text-field\" 
id=\"jp-carousel-comment-form-url-field\" 
\/><\/fieldset>","reblog":"Reblog","reblogged":"Reblogged","reblog_add_thoughts":"Add
 your thoughts here... 
(optional)","reblogging":"Reblogging...","post_reblog":"Post 
Reblog","stats_query_args":"blog=22872755&v=wpcom&tz=-8&user_id=0&subd=probablydance","is_public":"1","reblog_enabled":""};
/*
 ]]> */
</script>
<script type="text/javascript">
/* <![CDATA[ */
var sharing_js_options = {"lang":"en","counts":"1"};
/* ]]> */
</script>
<script type="text/javascript" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/a_002"></script><div id="actionbar" class="actnbr-pub-manifest actnbr-has-follow actnbr-hidden"><ul><li class="actnbr-btn actnbr-hidden"> 			    	<a class="actnbr-action actnbr-actn-follow" href=""><svg class="gridicon gridicon__follow" height="24px" width="24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M23 16v2h-3v3h-2v-3h-3v-2h3v-3h2v3h3zM20 2v9h-4v3h-3v4H4c-1.1 0-2-.9-2-2V2h18zM8 13v-1H4v1h4zm3-3H4v1h7v-1zm0-2H4v1h7V8zm7-4H4v2h14V4z"></path></g></svg><span>Follow</span></a> 			    	<div class="actnbr-popover tip tip-top-left actnbr-notice"> 			    		<div class="tip-arrow"></div> 			    		<div class="tip-inner actnbr-follow-bubble"></div> 			    	</div> 			    </li><li class="actnbr-ellipsis actnbr-hidden"> 			  <svg class="gridicon gridicon__ellipsis" height="24" width="24" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><circle cx="5" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="12" cy="12" r="2"></circle></g></svg> 			  <div class="actnbr-popover tip tip-top-left actnbr-more"> 			  	<div class="tip-arrow"></div> 			  	<div class="tip-inner"> 				  <ul> 				    <li class="actnbr-sitename actnbr-hidden"><a href="https://probablydance.com/"><img alt="" src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/wpcom-gray-white.png" class="avatar avatar-50" width="50" height="50"> Probably Dance</a></li> 				   	<li class="actnbr-folded-customize actnbr-hidden"><a href="https://probablydance.wordpress.com/wp-admin/customize.php?url=https%3A%2F%2Fprobablydance.wordpress.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F"><svg class="gridicon gridicon__customize" height="20px" width="20px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M2 6c0-1.505.78-3.08 2-4 0 .845.69 2 2 2 1.657 0 3 1.343 3 3 0 .386-.08.752-.212 1.09.74.594 1.476 1.19 2.19 1.81L8.9 11.98c-.62-.716-1.214-1.454-1.807-2.192C6.753 9.92 6.387 10 6 10c-2.21 0-4-1.79-4-4zm12.152 6.848l1.34-1.34c.607.304 1.283.492 2.008.492 2.485 0 4.5-2.015 4.5-4.5 0-.725-.188-1.4-.493-2.007L18 9l-2-2 3.507-3.507C18.9 3.188 18.225 3 17.5 3 15.015 3 13 5.015 13 7.5c0 .725.188 1.4.493 2.007L3 20l2 2 6.848-6.848c1.885 1.928 3.874 3.753 5.977 5.45l1.425 1.148 1.5-1.5-1.15-1.425c-1.695-2.103-3.52-4.092-5.448-5.977z" data-reactid=".2.1.1:0.1b.0"></path></g></svg><span>Customize<span></span></span></a></li> 				    <li class="actnbr-folded-follow actnbr-hidden"><a class="actnbr-action actnbr-actn-follow" href=""><svg class="gridicon gridicon__follow" height="24px" width="24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><g><path d="M23 16v2h-3v3h-2v-3h-3v-2h3v-3h2v3h3zM20 2v9h-4v3h-3v4H4c-1.1 0-2-.9-2-2V2h18zM8 13v-1H4v1h4zm3-3H4v1h7v-1zm0-2H4v1h7V8zm7-4H4v2h14V4z"></path></g></svg><span>Follow</span></a></li> 					<li class="actnbr-signup actnbr-hidden"><a href="https://wordpress.com/start/">Sign up</a></li> 				    <li class="actnbr-login actnbr-hidden"><a href="https://probablydance.wordpress.com/wp-login.php?redirect_to=https%3A%2F%2Fprobablydance.com%2F2016%2F04%2F30%2Fneural-networks-are-impressively-good-at-compression%2F">Log in</a></li> 				     				    <li class="actnbr-shortlink actnbr-hidden"><a href="https://wp.me/p1xYfp-Dh">Copy shortlink</a></li> 				    <li class="flb-report actnbr-hidden"><a href="http://en.wordpress.com/abuse/">Report this content</a></li> 				     				     				    <li class="actnbr-subs actnbr-hidden"><a href="https://subscribe.wordpress.com/">Manage subscriptions</a></li> 				    <li class="actnbr-fold actnbr-hidden"><a href="">Collapse this bar</a></li> 			      </ul> 			    </div> 		      </div> 		    </li> 	      </ul></div>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script>		<iframe src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/master.html" scrolling="no" id="likes-master" name="likes-master" style="display:none;"></iframe>
		<div id="likes-other-gravatars"><div class="likes-text"><span>%d</span> bloggers like this:</div><ul class="wpl-avatars sd-like-gravatars"></ul></div>
<script src="Neural%20Networks%20Are%20Impressively%20Good%20At%20Compression%20|%20Probably%20Dance_files/w.js" type="text/javascript" async="" defer="defer"></script>
<script type="text/javascript">
_tkq = window._tkq || [];
_stq = window._stq || [];
_tkq.push(['storeContext', 
{'blog_id':'22872755','blog_tz':'-8','user_lang':'en','blog_lang':'en','user_id':'0'}]);
_stq.push(['view',
 
{'blog':'22872755','v':'wpcom','tz':'-8','user_id':'0','post':'2435','subd':'probablydance'}]);
_stq.push(['extra',
 
{'crypt':'UE40eW5QN0p8M2Y/RE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGRVYVNrSFguN3FwSmQ5RGtNX3VQcj1yVzhiflM1THQtLGFdQ2toOXYlSHRwW3lOSlk5cVNSfnJIX21fV01OJiV3cixaZ1Vnd2FoamgtJSZbLTksQj9fK0t+JlNrbWJEb11vQ3BlZl02dyxIUG5kK0JRQ3FoTmw0Mm0/KytwXWxCR1ZWLzBiN28tLiVoUktlNjZYWnpucV1RZjkmLnNkaCtialNYfG41cytwY3hqWzhOR0lKLmdMel9nMENtazhrX1UsU2p1RFp4YVl6PTl8eEtmc3VCbWU2Q0NbeXplTk1VZlpHUkl0eXhvUmc5Z2VdVHFRWDFQd0w5R2Y9QmFv'}]);
_stq.push([
 'clickTrackerInit', '22872755', '2435' ]);
	</script>
<noscript><img src="https://pixel.wp.com/b.gif?v=noscript" style="height:0px;width:0px;overflow:hidden" alt="" /></noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + 
wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + 
wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + 
'//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba='
 + Math.random();
	}
	
}
</script>



</body></html>
<!--
	generated in 0.211 seconds
	109981 bytes batcached for 300 seconds
-->